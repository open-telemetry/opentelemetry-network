// Auto-generated by Render: Rust FFI for ebpf_net::logging
#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_variables)]
#[allow(unused_imports)]
use crate::JbBlob;

use crate::wire_messages::*;

use core::slice;

#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_logger_start(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__logger_start = jb_logging__logger_start {
        _rpc_id: 600 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_logger_end(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__logger_end = jb_logging__logger_end {
        _rpc_id: 601 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_lost_events(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    count: u32,
    client_hostname: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agent_lost_events = jb_logging__agent_lost_events {
        _rpc_id: 602 as u16,
        _len: __consumed as u16,
        count,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_pod_not_found(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    uid: JbBlob,
    on_delete: u8,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(uid.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__pod_not_found = jb_logging__pod_not_found {
        _rpc_id: 603 as u16,
        _len: __consumed as u16,
        on_delete,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_uid.is_empty() {
        let __len = __sl_uid.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_uid);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_cgroup_not_found(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    cgroup: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 24 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__cgroup_not_found = jb_logging__cgroup_not_found {
        _rpc_id: 604 as u16,
        cgroup,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 24 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 24 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rewriting_private_to_public_ip_mapping(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    private_addr: JbBlob,
    existing_public_addr: JbBlob,
    new_public_addr: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(private_addr.len as u32);
    __consumed = __consumed.saturating_add(existing_public_addr.len as u32);
    __consumed = __consumed.saturating_add(new_public_addr.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_private_addr: &[u8] =
        unsafe { slice::from_raw_parts(private_addr.buf as *const u8, private_addr.len as usize) };
    let __sl_existing_public_addr: &[u8] = unsafe {
        slice::from_raw_parts(
            existing_public_addr.buf as *const u8,
            existing_public_addr.len as usize,
        )
    };
    let __sl_new_public_addr: &[u8] = unsafe {
        slice::from_raw_parts(
            new_public_addr.buf as *const u8,
            new_public_addr.len as usize,
        )
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__rewriting_private_to_public_ip_mapping =
        jb_logging__rewriting_private_to_public_ip_mapping {
            _rpc_id: 605 as u16,
            _len: __consumed as u16,
            private_addr: (__sl_private_addr.len() as u16),
            existing_public_addr: (__sl_existing_public_addr.len() as u16),
            _ref,
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_private_addr.is_empty() {
        let __len = __sl_private_addr.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_private_addr);
        __off += __len;
    }
    if !__sl_existing_public_addr.is_empty() {
        let __len = __sl_existing_public_addr.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_existing_public_addr);
        __off += __len;
    }
    if !__sl_new_public_addr.is_empty() {
        let __len = __sl_new_public_addr.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_new_public_addr);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_private_ip_in_private_to_public_ip_mapping(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    private_addr: JbBlob,
    existing_public_addr: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(private_addr.len as u32);
    __consumed = __consumed.saturating_add(existing_public_addr.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_private_addr: &[u8] =
        unsafe { slice::from_raw_parts(private_addr.buf as *const u8, private_addr.len as usize) };
    let __sl_existing_public_addr: &[u8] = unsafe {
        slice::from_raw_parts(
            existing_public_addr.buf as *const u8,
            existing_public_addr.len as usize,
        )
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__private_ip_in_private_to_public_ip_mapping =
        jb_logging__private_ip_in_private_to_public_ip_mapping {
            _rpc_id: 606 as u16,
            _len: __consumed as u16,
            private_addr: (__sl_private_addr.len() as u16),
            _ref,
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_private_addr.is_empty() {
        let __len = __sl_private_addr.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_private_addr);
        __off += __len;
    }
    if !__sl_existing_public_addr.is_empty() {
        let __len = __sl_existing_public_addr.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_existing_public_addr);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_failed_to_insert_dns_record(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__failed_to_insert_dns_record = jb_logging__failed_to_insert_dns_record {
        _rpc_id: 607 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_tcp_socket_failed_getting_process_reference(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    pid: u32,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__tcp_socket_failed_getting_process_reference =
        jb_logging__tcp_socket_failed_getting_process_reference {
            _rpc_id: 608 as u16,
            pid,
            _ref,
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_udp_socket_failed_getting_process_reference(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    pid: u32,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__udp_socket_failed_getting_process_reference =
        jb_logging__udp_socket_failed_getting_process_reference {
            _rpc_id: 609 as u16,
            pid,
            _ref,
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_socket_address_already_assigned(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__socket_address_already_assigned =
        jb_logging__socket_address_already_assigned {
            _rpc_id: 610 as u16,
            _ref,
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_decompression_error(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    client_type: u8,
    client_hostname: JbBlob,
    error: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    __consumed = __consumed.saturating_add(error.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };
    let __sl_error: &[u8] =
        unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__ingest_decompression_error = jb_logging__ingest_decompression_error {
        _rpc_id: 611 as u16,
        _len: __consumed as u16,
        client_hostname: (__sl_client_hostname.len() as u16),
        client_type,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
    if !__sl_error.is_empty() {
        let __len = __sl_error.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_error);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_processing_error(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    client_type: u8,
    client_hostname: JbBlob,
    error: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    __consumed = __consumed.saturating_add(error.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };
    let __sl_error: &[u8] =
        unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__ingest_processing_error = jb_logging__ingest_processing_error {
        _rpc_id: 612 as u16,
        _len: __consumed as u16,
        client_hostname: (__sl_client_hostname.len() as u16),
        client_type,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
    if !__sl_error.is_empty() {
        let __len = __sl_error.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_error);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_connection_error(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    client_type: u8,
    client_hostname: JbBlob,
    error: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    __consumed = __consumed.saturating_add(error.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };
    let __sl_error: &[u8] =
        unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__ingest_connection_error = jb_logging__ingest_connection_error {
        _rpc_id: 613 as u16,
        _len: __consumed as u16,
        client_hostname: (__sl_client_hostname.len() as u16),
        client_type,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
    if !__sl_error.is_empty() {
        let __len = __sl_error.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_error);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_auth_success(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    client_type: u8,
    client_hostname: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agent_auth_success = jb_logging__agent_auth_success {
        _rpc_id: 614 as u16,
        _len: __consumed as u16,
        client_type,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_auth_failure(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    client_type: u8,
    client_hostname: JbBlob,
    error: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    __consumed = __consumed.saturating_add(error.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };
    let __sl_error: &[u8] =
        unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agent_auth_failure = jb_logging__agent_auth_failure {
        _rpc_id: 615 as u16,
        _len: __consumed as u16,
        client_hostname: (__sl_client_hostname.len() as u16),
        client_type,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
    if !__sl_error.is_empty() {
        let __len = __sl_error.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_error);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_attempting_auth_using_api_key(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    client_type: u8,
    client_hostname: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agent_attempting_auth_using_api_key =
        jb_logging__agent_attempting_auth_using_api_key {
            _rpc_id: 616 as u16,
            _len: __consumed as u16,
            client_type,
            _ref,
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_k8s_container_pod_not_found(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    pod_uid_suffix: *const u8,
    pod_uid_hash: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 88 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_pod_uid_suffix: &[u8] = unsafe { slice::from_raw_parts(pod_uid_suffix, 64) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__k8s_container_pod_not_found = jb_logging__k8s_container_pod_not_found {
        _rpc_id: 617 as u16,
        pod_uid_suffix: __sl_pod_uid_suffix.try_into().unwrap(),
        pod_uid_hash,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 88 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 88 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_connect_success(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    client_type: u8,
    client_hostname: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 16 as u32;
    __consumed = __consumed.saturating_add(client_hostname.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_client_hostname: &[u8] = unsafe {
        slice::from_raw_parts(
            client_hostname.buf as *const u8,
            client_hostname.len as usize,
        )
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agent_connect_success = jb_logging__agent_connect_success {
        _rpc_id: 618 as u16,
        _len: __consumed as u16,
        client_type,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_client_hostname.is_empty() {
        let __len = __sl_client_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_hostname);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_core_stats_start(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__core_stats_start = jb_logging__core_stats_start {
        _rpc_id: 619 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_core_stats_end(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__core_stats_end = jb_logging__core_stats_end {
        _rpc_id: 620 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_span_utilization_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    span_name: JbBlob,
    module: JbBlob,
    shard: u16,
    allocated: u16,
    max_allocated: u16,
    pool_size_: u16,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 30 as u32;
    __consumed = __consumed.saturating_add(span_name.len as u32);
    __consumed = __consumed.saturating_add(module.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_span_name: &[u8] =
        unsafe { slice::from_raw_parts(span_name.buf as *const u8, span_name.len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__span_utilization_stats = jb_logging__span_utilization_stats {
        _rpc_id: 621 as u16,
        _len: __consumed as u16,
        span_name: (__sl_span_name.len() as u16),
        shard,
        time_ns,
        _ref,
        allocated,
        max_allocated,
        pool_size_,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 30 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 30 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_span_name.is_empty() {
        let __len = __sl_span_name.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_span_name);
        __off += __len;
    }
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_connection_message_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    msg_: JbBlob,
    shard: u16,
    severity_: u32,
    conn: u16,
    time_ns: u64,
    count: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 38 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(msg_.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_msg_: &[u8] =
        unsafe { slice::from_raw_parts(msg_.buf as *const u8, msg_.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__connection_message_stats = jb_logging__connection_message_stats {
        _rpc_id: 622 as u16,
        _len: __consumed as u16,
        severity_,
        time_ns,
        count,
        _ref,
        module: (__sl_module.len() as u16),
        shard,
        conn,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 38 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 38 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_msg_.is_empty() {
        let __len = __sl_msg_.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_msg_);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_connection_message_error_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    conn: u16,
    msg_: JbBlob,
    error: JbBlob,
    count: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 36 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(msg_.len as u32);
    __consumed = __consumed.saturating_add(error.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_msg_: &[u8] =
        unsafe { slice::from_raw_parts(msg_.buf as *const u8, msg_.len as usize) };
    let __sl_error: &[u8] =
        unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__connection_message_error_stats =
        jb_logging__connection_message_error_stats {
            _rpc_id: 623 as u16,
            _len: __consumed as u16,
            module: (__sl_module.len() as u16),
            shard,
            count,
            time_ns,
            _ref,
            conn,
            msg_: (__sl_msg_.len() as u16),
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 36 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 36 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_msg_.is_empty() {
        let __len = __sl_msg_.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_msg_);
        __off += __len;
    }
    if !__sl_error.is_empty() {
        let __len = __sl_error.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_error);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_status_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    program: JbBlob,
    version: JbBlob,
    status: u8,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 27 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(program.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_program: &[u8] =
        unsafe { slice::from_raw_parts(program.buf as *const u8, program.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__status_stats = jb_logging__status_stats {
        _rpc_id: 624 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        time_ns,
        _ref,
        program: (__sl_program.len() as u16),
        status,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 27 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 27 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_program.is_empty() {
        let __len = __sl_program.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_program);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rpc_receive_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    receiver_app: JbBlob,
    shard: u16,
    sender_app: JbBlob,
    max_latency_ns: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 32 as u32;
    __consumed = __consumed.saturating_add(receiver_app.len as u32);
    __consumed = __consumed.saturating_add(sender_app.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_receiver_app: &[u8] =
        unsafe { slice::from_raw_parts(receiver_app.buf as *const u8, receiver_app.len as usize) };
    let __sl_sender_app: &[u8] =
        unsafe { slice::from_raw_parts(sender_app.buf as *const u8, sender_app.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__rpc_receive_stats = jb_logging__rpc_receive_stats {
        _rpc_id: 625 as u16,
        _len: __consumed as u16,
        receiver_app: (__sl_receiver_app.len() as u16),
        shard,
        max_latency_ns,
        time_ns,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 32 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_receiver_app.is_empty() {
        let __len = __sl_receiver_app.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_receiver_app);
        __off += __len;
    }
    if !__sl_sender_app.is_empty() {
        let __len = __sl_sender_app.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_sender_app);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rpc_write_stalls_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    sender_app: JbBlob,
    shard: u16,
    receiver_app: JbBlob,
    count: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 32 as u32;
    __consumed = __consumed.saturating_add(sender_app.len as u32);
    __consumed = __consumed.saturating_add(receiver_app.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_sender_app: &[u8] =
        unsafe { slice::from_raw_parts(sender_app.buf as *const u8, sender_app.len as usize) };
    let __sl_receiver_app: &[u8] =
        unsafe { slice::from_raw_parts(receiver_app.buf as *const u8, receiver_app.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__rpc_write_stalls_stats = jb_logging__rpc_write_stalls_stats {
        _rpc_id: 626 as u16,
        _len: __consumed as u16,
        sender_app: (__sl_sender_app.len() as u16),
        shard,
        count,
        time_ns,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 32 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_sender_app.is_empty() {
        let __len = __sl_sender_app.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_sender_app);
        __off += __len;
    }
    if !__sl_receiver_app.is_empty() {
        let __len = __sl_receiver_app.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_receiver_app);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rpc_write_utilization_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    sender_app: JbBlob,
    shard: u16,
    receiver_app: JbBlob,
    max_buf_used: u32,
    max_buf_util: u64,
    max_elem_util: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 44 as u32;
    __consumed = __consumed.saturating_add(sender_app.len as u32);
    __consumed = __consumed.saturating_add(receiver_app.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_sender_app: &[u8] =
        unsafe { slice::from_raw_parts(sender_app.buf as *const u8, sender_app.len as usize) };
    let __sl_receiver_app: &[u8] =
        unsafe { slice::from_raw_parts(receiver_app.buf as *const u8, receiver_app.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__rpc_write_utilization_stats = jb_logging__rpc_write_utilization_stats {
        _rpc_id: 627 as u16,
        _len: __consumed as u16,
        max_buf_used,
        max_buf_util,
        max_elem_util,
        time_ns,
        _ref,
        sender_app: (__sl_sender_app.len() as u16),
        shard,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 44 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 44 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_sender_app.is_empty() {
        let __len = __sl_sender_app.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_sender_app);
        __off += __len;
    }
    if !__sl_receiver_app.is_empty() {
        let __len = __sl_receiver_app.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_receiver_app);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_code_timing_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    name: JbBlob,
    filename: JbBlob,
    line: u16,
    index_string: u64,
    count: u64,
    avg_ns: u64,
    min_ns: u64,
    sum_ns: u64,
    max_ns: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 72 as u32;
    __consumed = __consumed.saturating_add(name.len as u32);
    __consumed = __consumed.saturating_add(filename.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_name: &[u8] =
        unsafe { slice::from_raw_parts(name.buf as *const u8, name.len as usize) };
    let __sl_filename: &[u8] =
        unsafe { slice::from_raw_parts(filename.buf as *const u8, filename.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__code_timing_stats = jb_logging__code_timing_stats {
        _rpc_id: 628 as u16,
        _len: __consumed as u16,
        name: (__sl_name.len() as u16),
        line,
        index_string,
        count,
        avg_ns,
        min_ns,
        max_ns,
        sum_ns,
        time_ns,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 72 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 72 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_name.is_empty() {
        let __len = __sl_name.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_name);
        __off += __len;
    }
    if !__sl_filename.is_empty() {
        let __len = __sl_filename.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_filename);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_core_stats_start(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agg_core_stats_start = jb_logging__agg_core_stats_start {
        _rpc_id: 629 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_core_stats_end(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agg_core_stats_end = jb_logging__agg_core_stats_end {
        _rpc_id: 630 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_root_truncation_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    field: JbBlob,
    count: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 32 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(field.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_field: &[u8] =
        unsafe { slice::from_raw_parts(field.buf as *const u8, field.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agg_root_truncation_stats = jb_logging__agg_root_truncation_stats {
        _rpc_id: 631 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        count,
        time_ns,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 32 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_field.is_empty() {
        let __len = __sl_field.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_field);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_prometheus_bytes_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    prometheus_bytes_written: u64,
    prometheus_bytes_discarded: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 40 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agg_prometheus_bytes_stats = jb_logging__agg_prometheus_bytes_stats {
        _rpc_id: 632 as u16,
        _len: __consumed as u16,
        shard,
        prometheus_bytes_written,
        prometheus_bytes_discarded,
        time_ns,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 40 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 40 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_otlp_grpc_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    client_type: JbBlob,
    bytes_failed: u64,
    bytes_sent: u64,
    data_points_failed: u64,
    data_points_sent: u64,
    requests_failed: u64,
    requests_sent: u64,
    unknown_response_tags: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 80 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(client_type.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_client_type: &[u8] =
        unsafe { slice::from_raw_parts(client_type.buf as *const u8, client_type.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agg_otlp_grpc_stats = jb_logging__agg_otlp_grpc_stats {
        _rpc_id: 644 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        bytes_failed,
        bytes_sent,
        data_points_failed,
        data_points_sent,
        requests_failed,
        requests_sent,
        unknown_response_tags,
        time_ns,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 80 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 80 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_client_type.is_empty() {
        let __len = __sl_client_type.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_client_type);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_core_stats_start(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__ingest_core_stats_start = jb_logging__ingest_core_stats_start {
        _rpc_id: 633 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_core_stats_end(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__ingest_core_stats_end = jb_logging__ingest_core_stats_end {
        _rpc_id: 634 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_client_handle_pool_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    span_name: JbBlob,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    agent_hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    client_handle_pool: u64,
    client_handle_pool_fraction: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 62 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(span_name.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(agent_hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_span_name: &[u8] =
        unsafe { slice::from_raw_parts(span_name.buf as *const u8, span_name.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_agent_hostname: &[u8] = unsafe {
        slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize)
    };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__client_handle_pool_stats = jb_logging__client_handle_pool_stats {
        _rpc_id: 635 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        time_ns,
        client_handle_pool,
        client_handle_pool_fraction,
        _ref,
        span_name: (__sl_span_name.len() as u16),
        version: (__sl_version.len() as u16),
        cloud: (__sl_cloud.len() as u16),
        env: (__sl_env.len() as u16),
        role: (__sl_role.len() as u16),
        az: (__sl_az.len() as u16),
        node_id: (__sl_node_id.len() as u16),
        kernel_version: (__sl_kernel_version.len() as u16),
        client_type,
        agent_hostname: (__sl_agent_hostname.len() as u16),
        os: (__sl_os.len() as u16),
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 62 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 62 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_span_name.is_empty() {
        let __len = __sl_span_name.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_span_name);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_agent_hostname.is_empty() {
        let __len = __sl_agent_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_agent_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_connection_message_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    agent_hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    message: JbBlob,
    severity_: u16,
    count: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 56 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(agent_hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    __consumed = __consumed.saturating_add(message.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_agent_hostname: &[u8] = unsafe {
        slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize)
    };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
    let __sl_message: &[u8] =
        unsafe { slice::from_raw_parts(message.buf as *const u8, message.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agent_connection_message_stats =
        jb_logging__agent_connection_message_stats {
            _rpc_id: 636 as u16,
            _len: __consumed as u16,
            module: (__sl_module.len() as u16),
            shard,
            time_ns,
            count,
            _ref,
            version: (__sl_version.len() as u16),
            cloud: (__sl_cloud.len() as u16),
            env: (__sl_env.len() as u16),
            role: (__sl_role.len() as u16),
            az: (__sl_az.len() as u16),
            node_id: (__sl_node_id.len() as u16),
            kernel_version: (__sl_kernel_version.len() as u16),
            client_type,
            agent_hostname: (__sl_agent_hostname.len() as u16),
            os: (__sl_os.len() as u16),
            os_version: (__sl_os_version.len() as u16),
            severity_,
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 56 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 56 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_agent_hostname.is_empty() {
        let __len = __sl_agent_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_agent_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
    if !__sl_message.is_empty() {
        let __len = __sl_message.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_message);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_connection_message_error_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    agent_hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    message: JbBlob,
    error: JbBlob,
    count: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 56 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(agent_hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    __consumed = __consumed.saturating_add(message.len as u32);
    __consumed = __consumed.saturating_add(error.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_agent_hostname: &[u8] = unsafe {
        slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize)
    };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
    let __sl_message: &[u8] =
        unsafe { slice::from_raw_parts(message.buf as *const u8, message.len as usize) };
    let __sl_error: &[u8] =
        unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__agent_connection_message_error_stats =
        jb_logging__agent_connection_message_error_stats {
            _rpc_id: 637 as u16,
            _len: __consumed as u16,
            module: (__sl_module.len() as u16),
            shard,
            time_ns,
            count,
            _ref,
            version: (__sl_version.len() as u16),
            cloud: (__sl_cloud.len() as u16),
            env: (__sl_env.len() as u16),
            role: (__sl_role.len() as u16),
            az: (__sl_az.len() as u16),
            node_id: (__sl_node_id.len() as u16),
            kernel_version: (__sl_kernel_version.len() as u16),
            client_type,
            agent_hostname: (__sl_agent_hostname.len() as u16),
            os: (__sl_os.len() as u16),
            os_version: (__sl_os_version.len() as u16),
            message: (__sl_message.len() as u16),
        };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 56 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 56 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_agent_hostname.is_empty() {
        let __len = __sl_agent_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_agent_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
    if !__sl_message.is_empty() {
        let __len = __sl_message.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_message);
        __off += __len;
    }
    if !__sl_error.is_empty() {
        let __len = __sl_error.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_error);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_connection_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    agent_hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    time_since_last_message_ns: u64,
    clock_offset_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 60 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(agent_hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_agent_hostname: &[u8] = unsafe {
        slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize)
    };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__connection_stats = jb_logging__connection_stats {
        _rpc_id: 638 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        time_ns,
        time_since_last_message_ns,
        clock_offset_ns,
        _ref,
        version: (__sl_version.len() as u16),
        cloud: (__sl_cloud.len() as u16),
        env: (__sl_env.len() as u16),
        role: (__sl_role.len() as u16),
        az: (__sl_az.len() as u16),
        node_id: (__sl_node_id.len() as u16),
        kernel_version: (__sl_kernel_version.len() as u16),
        client_type,
        agent_hostname: (__sl_agent_hostname.len() as u16),
        os: (__sl_os.len() as u16),
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 60 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 60 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_agent_hostname.is_empty() {
        let __len = __sl_agent_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_agent_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_collector_log_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    agent_hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    severity_: JbBlob,
    count: u32,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 50 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(agent_hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    __consumed = __consumed.saturating_add(severity_.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_agent_hostname: &[u8] = unsafe {
        slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize)
    };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
    let __sl_severity_: &[u8] =
        unsafe { slice::from_raw_parts(severity_.buf as *const u8, severity_.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__collector_log_stats = jb_logging__collector_log_stats {
        _rpc_id: 639 as u16,
        _len: __consumed as u16,
        count,
        time_ns,
        _ref,
        module: (__sl_module.len() as u16),
        shard,
        version: (__sl_version.len() as u16),
        cloud: (__sl_cloud.len() as u16),
        env: (__sl_env.len() as u16),
        role: (__sl_role.len() as u16),
        az: (__sl_az.len() as u16),
        node_id: (__sl_node_id.len() as u16),
        kernel_version: (__sl_kernel_version.len() as u16),
        client_type,
        agent_hostname: (__sl_agent_hostname.len() as u16),
        os: (__sl_os.len() as u16),
        os_version: (__sl_os_version.len() as u16),
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 50 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 50 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_agent_hostname.is_empty() {
        let __len = __sl_agent_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_agent_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
    if !__sl_severity_.is_empty() {
        let __len = __sl_severity_.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_severity_);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_entry_point_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    agent_hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    kernel_headers_source: JbBlob,
    entrypoint_error: JbBlob,
    entrypoint_info: u8,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 49 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(agent_hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    __consumed = __consumed.saturating_add(kernel_headers_source.len as u32);
    __consumed = __consumed.saturating_add(entrypoint_error.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_agent_hostname: &[u8] = unsafe {
        slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize)
    };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
    let __sl_kernel_headers_source: &[u8] = unsafe {
        slice::from_raw_parts(
            kernel_headers_source.buf as *const u8,
            kernel_headers_source.len as usize,
        )
    };
    let __sl_entrypoint_error: &[u8] = unsafe {
        slice::from_raw_parts(
            entrypoint_error.buf as *const u8,
            entrypoint_error.len as usize,
        )
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__entry_point_stats = jb_logging__entry_point_stats {
        _rpc_id: 640 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        time_ns,
        _ref,
        version: (__sl_version.len() as u16),
        cloud: (__sl_cloud.len() as u16),
        env: (__sl_env.len() as u16),
        role: (__sl_role.len() as u16),
        az: (__sl_az.len() as u16),
        node_id: (__sl_node_id.len() as u16),
        kernel_version: (__sl_kernel_version.len() as u16),
        client_type,
        agent_hostname: (__sl_agent_hostname.len() as u16),
        os: (__sl_os.len() as u16),
        os_version: (__sl_os_version.len() as u16),
        kernel_headers_source: (__sl_kernel_headers_source.len() as u16),
        entrypoint_info,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 49 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 49 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_agent_hostname.is_empty() {
        let __len = __sl_agent_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_agent_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
    if !__sl_kernel_headers_source.is_empty() {
        let __len = __sl_kernel_headers_source.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_headers_source);
        __off += __len;
    }
    if !__sl_entrypoint_error.is_empty() {
        let __len = __sl_entrypoint_error.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_entrypoint_error);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_collector_health_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    status: JbBlob,
    status_detail: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 48 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    __consumed = __consumed.saturating_add(status.len as u32);
    __consumed = __consumed.saturating_add(status_detail.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_hostname: &[u8] =
        unsafe { slice::from_raw_parts(hostname.buf as *const u8, hostname.len as usize) };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
    let __sl_status: &[u8] =
        unsafe { slice::from_raw_parts(status.buf as *const u8, status.len as usize) };
    let __sl_status_detail: &[u8] = unsafe {
        slice::from_raw_parts(status_detail.buf as *const u8, status_detail.len as usize)
    };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__collector_health_stats = jb_logging__collector_health_stats {
        _rpc_id: 641 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        time_ns,
        _ref,
        version: (__sl_version.len() as u16),
        cloud: (__sl_cloud.len() as u16),
        env: (__sl_env.len() as u16),
        role: (__sl_role.len() as u16),
        az: (__sl_az.len() as u16),
        node_id: (__sl_node_id.len() as u16),
        kernel_version: (__sl_kernel_version.len() as u16),
        client_type,
        hostname: (__sl_hostname.len() as u16),
        os: (__sl_os.len() as u16),
        os_version: (__sl_os_version.len() as u16),
        status: (__sl_status.len() as u16),
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 48 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 48 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_hostname.is_empty() {
        let __len = __sl_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
    if !__sl_status.is_empty() {
        let __len = __sl_status.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_status);
        __off += __len;
    }
    if !__sl_status_detail.is_empty() {
        let __len = __sl_status_detail.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_status_detail);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_bpf_log_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    shard: u16,
    version: JbBlob,
    cloud: JbBlob,
    env: JbBlob,
    role: JbBlob,
    az: JbBlob,
    node_id: JbBlob,
    kernel_version: JbBlob,
    client_type: u16,
    hostname: JbBlob,
    os: JbBlob,
    os_version: JbBlob,
    time_ns: u64,
    filename: JbBlob,
    line: JbBlob,
    code: JbBlob,
    arg0: JbBlob,
    arg1: JbBlob,
    arg2: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 56 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(cloud.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(node_id.len as u32);
    __consumed = __consumed.saturating_add(kernel_version.len as u32);
    __consumed = __consumed.saturating_add(hostname.len as u32);
    __consumed = __consumed.saturating_add(os.len as u32);
    __consumed = __consumed.saturating_add(os_version.len as u32);
    __consumed = __consumed.saturating_add(filename.len as u32);
    __consumed = __consumed.saturating_add(line.len as u32);
    __consumed = __consumed.saturating_add(code.len as u32);
    __consumed = __consumed.saturating_add(arg0.len as u32);
    __consumed = __consumed.saturating_add(arg1.len as u32);
    __consumed = __consumed.saturating_add(arg2.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_cloud: &[u8] =
        unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_node_id: &[u8] =
        unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
    let __sl_kernel_version: &[u8] = unsafe {
        slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize)
    };
    let __sl_hostname: &[u8] =
        unsafe { slice::from_raw_parts(hostname.buf as *const u8, hostname.len as usize) };
    let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
    let __sl_os_version: &[u8] =
        unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
    let __sl_filename: &[u8] =
        unsafe { slice::from_raw_parts(filename.buf as *const u8, filename.len as usize) };
    let __sl_line: &[u8] =
        unsafe { slice::from_raw_parts(line.buf as *const u8, line.len as usize) };
    let __sl_code: &[u8] =
        unsafe { slice::from_raw_parts(code.buf as *const u8, code.len as usize) };
    let __sl_arg0: &[u8] =
        unsafe { slice::from_raw_parts(arg0.buf as *const u8, arg0.len as usize) };
    let __sl_arg1: &[u8] =
        unsafe { slice::from_raw_parts(arg1.buf as *const u8, arg1.len as usize) };
    let __sl_arg2: &[u8] =
        unsafe { slice::from_raw_parts(arg2.buf as *const u8, arg2.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__bpf_log_stats = jb_logging__bpf_log_stats {
        _rpc_id: 642 as u16,
        _len: __consumed as u16,
        module: (__sl_module.len() as u16),
        shard,
        time_ns,
        _ref,
        version: (__sl_version.len() as u16),
        cloud: (__sl_cloud.len() as u16),
        env: (__sl_env.len() as u16),
        role: (__sl_role.len() as u16),
        az: (__sl_az.len() as u16),
        node_id: (__sl_node_id.len() as u16),
        kernel_version: (__sl_kernel_version.len() as u16),
        client_type,
        hostname: (__sl_hostname.len() as u16),
        os: (__sl_os.len() as u16),
        os_version: (__sl_os_version.len() as u16),
        filename: (__sl_filename.len() as u16),
        line: (__sl_line.len() as u16),
        code: (__sl_code.len() as u16),
        arg0: (__sl_arg0.len() as u16),
        arg1: (__sl_arg1.len() as u16),
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 56 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 56 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_cloud.is_empty() {
        let __len = __sl_cloud.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_cloud);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_node_id.is_empty() {
        let __len = __sl_node_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_node_id);
        __off += __len;
    }
    if !__sl_kernel_version.is_empty() {
        let __len = __sl_kernel_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_kernel_version);
        __off += __len;
    }
    if !__sl_hostname.is_empty() {
        let __len = __sl_hostname.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_hostname);
        __off += __len;
    }
    if !__sl_os.is_empty() {
        let __len = __sl_os.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os);
        __off += __len;
    }
    if !__sl_os_version.is_empty() {
        let __len = __sl_os_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_os_version);
        __off += __len;
    }
    if !__sl_filename.is_empty() {
        let __len = __sl_filename.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_filename);
        __off += __len;
    }
    if !__sl_line.is_empty() {
        let __len = __sl_line.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_line);
        __off += __len;
    }
    if !__sl_code.is_empty() {
        let __len = __sl_code.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_code);
        __off += __len;
    }
    if !__sl_arg0.is_empty() {
        let __len = __sl_arg0.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_arg0);
        __off += __len;
    }
    if !__sl_arg1.is_empty() {
        let __len = __sl_arg1.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_arg1);
        __off += __len;
    }
    if !__sl_arg2.is_empty() {
        let __len = __sl_arg2.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_arg2);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_server_stats(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    module: JbBlob,
    connection_counter: u64,
    disconnect_counter: u64,
    time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 40 as u32;
    __consumed = __consumed.saturating_add(module.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_module: &[u8] =
        unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__server_stats = jb_logging__server_stats {
        _rpc_id: 643 as u16,
        _len: __consumed as u16,
        connection_counter,
        disconnect_counter,
        time_ns,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 40 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 40 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_module.is_empty() {
        let __len = __sl_module.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_module);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_pulse(__dest: *mut u8, __dest_len: u32, __tstamp: u64) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 2 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_logging__pulse = jb_logging__pulse {
        _rpc_id: 65535 as u16,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 2 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 2 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
