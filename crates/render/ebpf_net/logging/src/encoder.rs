// Auto-generated by Render: Rust FFI for ebpf_net::logging
#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_variables)]

#[allow(unused_imports)]
use crate::JbBlob;

use crate::wire_messages::*;

use core::slice;

#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_logger_start(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__logger_start = jb_logging__logger_start {
    _rpc_id: 600 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_logger_end(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__logger_end = jb_logging__logger_end {
    _rpc_id: 601 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_lost_events(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  count: u32,
  client_hostname: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agent_lost_events = jb_logging__agent_lost_events {
    _rpc_id: 602 as u16,
    _len: __consumed as u16,
    count,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_pod_not_found(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  uid: JbBlob,
  on_delete: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(uid.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__pod_not_found = jb_logging__pod_not_found {
    _rpc_id: 603 as u16,
    _len: __consumed as u16,
    on_delete,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_uid.is_empty() {
    let __len = __sl_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_uid);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_cgroup_not_found(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  cgroup: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 24 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__cgroup_not_found = jb_logging__cgroup_not_found {
    _rpc_id: 604 as u16,
    cgroup,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 24 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 24 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rewriting_private_to_public_ip_mapping(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  private_addr: JbBlob,
  existing_public_addr: JbBlob,
  new_public_addr: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(private_addr.len as u32);
  __consumed = __consumed.saturating_add(existing_public_addr.len as u32);
  __consumed = __consumed.saturating_add(new_public_addr.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_private_addr: &[u8] = unsafe { slice::from_raw_parts(private_addr.buf as *const u8, private_addr.len as usize) };
  let __sl_existing_public_addr: &[u8] = unsafe { slice::from_raw_parts(existing_public_addr.buf as *const u8, existing_public_addr.len as usize) };
  let __sl_new_public_addr: &[u8] = unsafe { slice::from_raw_parts(new_public_addr.buf as *const u8, new_public_addr.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__rewriting_private_to_public_ip_mapping = jb_logging__rewriting_private_to_public_ip_mapping {
    _rpc_id: 605 as u16,
    _len: __consumed as u16,
    private_addr: (__sl_private_addr.len() as u16),
    existing_public_addr: (__sl_existing_public_addr.len() as u16),
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_private_addr.is_empty() {
    let __len = __sl_private_addr.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_private_addr);
    __off += __len;
  }
  if !__sl_existing_public_addr.is_empty() {
    let __len = __sl_existing_public_addr.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_existing_public_addr);
    __off += __len;
  }
  if !__sl_new_public_addr.is_empty() {
    let __len = __sl_new_public_addr.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_new_public_addr);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_private_ip_in_private_to_public_ip_mapping(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  private_addr: JbBlob,
  existing_public_addr: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(private_addr.len as u32);
  __consumed = __consumed.saturating_add(existing_public_addr.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_private_addr: &[u8] = unsafe { slice::from_raw_parts(private_addr.buf as *const u8, private_addr.len as usize) };
  let __sl_existing_public_addr: &[u8] = unsafe { slice::from_raw_parts(existing_public_addr.buf as *const u8, existing_public_addr.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__private_ip_in_private_to_public_ip_mapping = jb_logging__private_ip_in_private_to_public_ip_mapping {
    _rpc_id: 606 as u16,
    _len: __consumed as u16,
    private_addr: (__sl_private_addr.len() as u16),
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_private_addr.is_empty() {
    let __len = __sl_private_addr.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_private_addr);
    __off += __len;
  }
  if !__sl_existing_public_addr.is_empty() {
    let __len = __sl_existing_public_addr.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_existing_public_addr);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_failed_to_insert_dns_record(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__failed_to_insert_dns_record = jb_logging__failed_to_insert_dns_record {
    _rpc_id: 607 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_tcp_socket_failed_getting_process_reference(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  pid: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__tcp_socket_failed_getting_process_reference = jb_logging__tcp_socket_failed_getting_process_reference {
    _rpc_id: 608 as u16,
    pid,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_udp_socket_failed_getting_process_reference(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  pid: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__udp_socket_failed_getting_process_reference = jb_logging__udp_socket_failed_getting_process_reference {
    _rpc_id: 609 as u16,
    pid,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_socket_address_already_assigned(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__socket_address_already_assigned = jb_logging__socket_address_already_assigned {
    _rpc_id: 610 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_decompression_error(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  client_type: u8,
  client_hostname: JbBlob,
  error: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  __consumed = __consumed.saturating_add(error.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };
  let __sl_error: &[u8] = unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__ingest_decompression_error = jb_logging__ingest_decompression_error {
    _rpc_id: 611 as u16,
    _len: __consumed as u16,
    client_hostname: (__sl_client_hostname.len() as u16),
    client_type,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
  if !__sl_error.is_empty() {
    let __len = __sl_error.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_error);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_processing_error(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  client_type: u8,
  client_hostname: JbBlob,
  error: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  __consumed = __consumed.saturating_add(error.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };
  let __sl_error: &[u8] = unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__ingest_processing_error = jb_logging__ingest_processing_error {
    _rpc_id: 612 as u16,
    _len: __consumed as u16,
    client_hostname: (__sl_client_hostname.len() as u16),
    client_type,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
  if !__sl_error.is_empty() {
    let __len = __sl_error.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_error);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_connection_error(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  client_type: u8,
  client_hostname: JbBlob,
  error: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  __consumed = __consumed.saturating_add(error.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };
  let __sl_error: &[u8] = unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__ingest_connection_error = jb_logging__ingest_connection_error {
    _rpc_id: 613 as u16,
    _len: __consumed as u16,
    client_hostname: (__sl_client_hostname.len() as u16),
    client_type,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
  if !__sl_error.is_empty() {
    let __len = __sl_error.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_error);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_auth_success(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  client_type: u8,
  client_hostname: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agent_auth_success = jb_logging__agent_auth_success {
    _rpc_id: 614 as u16,
    _len: __consumed as u16,
    client_type,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_auth_failure(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  client_type: u8,
  client_hostname: JbBlob,
  error: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  __consumed = __consumed.saturating_add(error.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };
  let __sl_error: &[u8] = unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agent_auth_failure = jb_logging__agent_auth_failure {
    _rpc_id: 615 as u16,
    _len: __consumed as u16,
    client_hostname: (__sl_client_hostname.len() as u16),
    client_type,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
  if !__sl_error.is_empty() {
    let __len = __sl_error.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_error);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_attempting_auth_using_api_key(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  client_type: u8,
  client_hostname: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agent_attempting_auth_using_api_key = jb_logging__agent_attempting_auth_using_api_key {
    _rpc_id: 616 as u16,
    _len: __consumed as u16,
    client_type,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_k8s_container_pod_not_found(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  pod_uid_suffix: *const u8,
  pod_uid_hash: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 88 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_pod_uid_suffix: &[u8] = unsafe { slice::from_raw_parts(pod_uid_suffix, 64) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__k8s_container_pod_not_found = jb_logging__k8s_container_pod_not_found {
    _rpc_id: 617 as u16,
    pod_uid_suffix: __sl_pod_uid_suffix.try_into().unwrap(),
    pod_uid_hash,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 88 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 88 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_connect_success(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  client_type: u8,
  client_hostname: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(client_hostname.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_client_hostname: &[u8] = unsafe { slice::from_raw_parts(client_hostname.buf as *const u8, client_hostname.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agent_connect_success = jb_logging__agent_connect_success {
    _rpc_id: 618 as u16,
    _len: __consumed as u16,
    client_type,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_client_hostname.is_empty() {
    let __len = __sl_client_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_hostname);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_core_stats_start(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__core_stats_start = jb_logging__core_stats_start {
    _rpc_id: 619 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_core_stats_end(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__core_stats_end = jb_logging__core_stats_end {
    _rpc_id: 620 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_span_utilization_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  span_name: JbBlob,
  module: JbBlob,
  shard: u16,
  allocated: u16,
  max_allocated: u16,
  pool_size_: u16,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 30 as u32;
  __consumed = __consumed.saturating_add(span_name.len as u32);
  __consumed = __consumed.saturating_add(module.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_span_name: &[u8] = unsafe { slice::from_raw_parts(span_name.buf as *const u8, span_name.len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__span_utilization_stats = jb_logging__span_utilization_stats {
    _rpc_id: 621 as u16,
    _len: __consumed as u16,
    span_name: (__sl_span_name.len() as u16),
    shard,
    time_ns,
    _ref,
    allocated,
    max_allocated,
    pool_size_
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 30 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 30 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_span_name.is_empty() {
    let __len = __sl_span_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_span_name);
    __off += __len;
  }
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_connection_message_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  msg_: JbBlob,
  shard: u16,
  severity_: u32,
  conn: u16,
  time_ns: u64,
  count: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 38 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(msg_.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_msg_: &[u8] = unsafe { slice::from_raw_parts(msg_.buf as *const u8, msg_.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__connection_message_stats = jb_logging__connection_message_stats {
    _rpc_id: 622 as u16,
    _len: __consumed as u16,
    severity_,
    time_ns,
    count,
    _ref,
    module: (__sl_module.len() as u16),
    shard,
    conn
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 38 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 38 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_msg_.is_empty() {
    let __len = __sl_msg_.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_msg_);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_connection_message_error_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  conn: u16,
  msg_: JbBlob,
  error: JbBlob,
  count: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 36 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(msg_.len as u32);
  __consumed = __consumed.saturating_add(error.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_msg_: &[u8] = unsafe { slice::from_raw_parts(msg_.buf as *const u8, msg_.len as usize) };
  let __sl_error: &[u8] = unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__connection_message_error_stats = jb_logging__connection_message_error_stats {
    _rpc_id: 623 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    count,
    time_ns,
    _ref,
    conn,
    msg_: (__sl_msg_.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 36 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 36 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_msg_.is_empty() {
    let __len = __sl_msg_.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_msg_);
    __off += __len;
  }
  if !__sl_error.is_empty() {
    let __len = __sl_error.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_error);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_status_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  program: JbBlob,
  version: JbBlob,
  status: u8,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 27 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(program.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_program: &[u8] = unsafe { slice::from_raw_parts(program.buf as *const u8, program.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__status_stats = jb_logging__status_stats {
    _rpc_id: 624 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    _ref,
    program: (__sl_program.len() as u16),
    status
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 27 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 27 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_program.is_empty() {
    let __len = __sl_program.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_program);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rpc_receive_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  receiver_app: JbBlob,
  shard: u16,
  sender_app: JbBlob,
  max_latency_ns: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 32 as u32;
  __consumed = __consumed.saturating_add(receiver_app.len as u32);
  __consumed = __consumed.saturating_add(sender_app.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_receiver_app: &[u8] = unsafe { slice::from_raw_parts(receiver_app.buf as *const u8, receiver_app.len as usize) };
  let __sl_sender_app: &[u8] = unsafe { slice::from_raw_parts(sender_app.buf as *const u8, sender_app.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__rpc_receive_stats = jb_logging__rpc_receive_stats {
    _rpc_id: 625 as u16,
    _len: __consumed as u16,
    receiver_app: (__sl_receiver_app.len() as u16),
    shard,
    max_latency_ns,
    time_ns,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 32 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_receiver_app.is_empty() {
    let __len = __sl_receiver_app.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_receiver_app);
    __off += __len;
  }
  if !__sl_sender_app.is_empty() {
    let __len = __sl_sender_app.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_sender_app);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rpc_write_stalls_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  sender_app: JbBlob,
  shard: u16,
  receiver_app: JbBlob,
  count: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 32 as u32;
  __consumed = __consumed.saturating_add(sender_app.len as u32);
  __consumed = __consumed.saturating_add(receiver_app.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_sender_app: &[u8] = unsafe { slice::from_raw_parts(sender_app.buf as *const u8, sender_app.len as usize) };
  let __sl_receiver_app: &[u8] = unsafe { slice::from_raw_parts(receiver_app.buf as *const u8, receiver_app.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__rpc_write_stalls_stats = jb_logging__rpc_write_stalls_stats {
    _rpc_id: 626 as u16,
    _len: __consumed as u16,
    sender_app: (__sl_sender_app.len() as u16),
    shard,
    count,
    time_ns,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 32 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_sender_app.is_empty() {
    let __len = __sl_sender_app.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_sender_app);
    __off += __len;
  }
  if !__sl_receiver_app.is_empty() {
    let __len = __sl_receiver_app.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_receiver_app);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_rpc_write_utilization_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  sender_app: JbBlob,
  shard: u16,
  receiver_app: JbBlob,
  max_buf_used: u32,
  max_buf_util: u64,
  max_elem_util: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 44 as u32;
  __consumed = __consumed.saturating_add(sender_app.len as u32);
  __consumed = __consumed.saturating_add(receiver_app.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_sender_app: &[u8] = unsafe { slice::from_raw_parts(sender_app.buf as *const u8, sender_app.len as usize) };
  let __sl_receiver_app: &[u8] = unsafe { slice::from_raw_parts(receiver_app.buf as *const u8, receiver_app.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__rpc_write_utilization_stats = jb_logging__rpc_write_utilization_stats {
    _rpc_id: 627 as u16,
    _len: __consumed as u16,
    max_buf_used,
    max_buf_util,
    max_elem_util,
    time_ns,
    _ref,
    sender_app: (__sl_sender_app.len() as u16),
    shard
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 44 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 44 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_sender_app.is_empty() {
    let __len = __sl_sender_app.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_sender_app);
    __off += __len;
  }
  if !__sl_receiver_app.is_empty() {
    let __len = __sl_receiver_app.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_receiver_app);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_code_timing_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  name: JbBlob,
  filename: JbBlob,
  line: u16,
  index_string: u64,
  count: u64,
  avg_ns: u64,
  min_ns: u64,
  sum_ns: u64,
  max_ns: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 72 as u32;
  __consumed = __consumed.saturating_add(name.len as u32);
  __consumed = __consumed.saturating_add(filename.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_name: &[u8] = unsafe { slice::from_raw_parts(name.buf as *const u8, name.len as usize) };
  let __sl_filename: &[u8] = unsafe { slice::from_raw_parts(filename.buf as *const u8, filename.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__code_timing_stats = jb_logging__code_timing_stats {
    _rpc_id: 628 as u16,
    _len: __consumed as u16,
    name: (__sl_name.len() as u16),
    line,
    index_string,
    count,
    avg_ns,
    min_ns,
    max_ns,
    sum_ns,
    time_ns,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 72 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 72 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_name.is_empty() {
    let __len = __sl_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_name);
    __off += __len;
  }
  if !__sl_filename.is_empty() {
    let __len = __sl_filename.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_filename);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_core_stats_start(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agg_core_stats_start = jb_logging__agg_core_stats_start {
    _rpc_id: 629 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_core_stats_end(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agg_core_stats_end = jb_logging__agg_core_stats_end {
    _rpc_id: 630 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_root_truncation_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  field: JbBlob,
  count: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 32 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(field.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_field: &[u8] = unsafe { slice::from_raw_parts(field.buf as *const u8, field.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agg_root_truncation_stats = jb_logging__agg_root_truncation_stats {
    _rpc_id: 631 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    count,
    time_ns,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 32 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_field.is_empty() {
    let __len = __sl_field.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_field);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_prometheus_bytes_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  prometheus_bytes_written: u64,
  prometheus_bytes_discarded: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 40 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agg_prometheus_bytes_stats = jb_logging__agg_prometheus_bytes_stats {
    _rpc_id: 632 as u16,
    _len: __consumed as u16,
    shard,
    prometheus_bytes_written,
    prometheus_bytes_discarded,
    time_ns,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 40 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 40 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agg_otlp_grpc_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  client_type: JbBlob,
  bytes_failed: u64,
  bytes_sent: u64,
  data_points_failed: u64,
  data_points_sent: u64,
  requests_failed: u64,
  requests_sent: u64,
  unknown_response_tags: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 80 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(client_type.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_client_type: &[u8] = unsafe { slice::from_raw_parts(client_type.buf as *const u8, client_type.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agg_otlp_grpc_stats = jb_logging__agg_otlp_grpc_stats {
    _rpc_id: 644 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    bytes_failed,
    bytes_sent,
    data_points_failed,
    data_points_sent,
    requests_failed,
    requests_sent,
    unknown_response_tags,
    time_ns,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 80 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 80 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_client_type.is_empty() {
    let __len = __sl_client_type.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_client_type);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_core_stats_start(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__ingest_core_stats_start = jb_logging__ingest_core_stats_start {
    _rpc_id: 633 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_ingest_core_stats_end(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__ingest_core_stats_end = jb_logging__ingest_core_stats_end {
    _rpc_id: 634 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_client_handle_pool_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  span_name: JbBlob,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  agent_hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  client_handle_pool: u64,
  client_handle_pool_fraction: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 62 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(span_name.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(agent_hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_span_name: &[u8] = unsafe { slice::from_raw_parts(span_name.buf as *const u8, span_name.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_agent_hostname: &[u8] = unsafe { slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__client_handle_pool_stats = jb_logging__client_handle_pool_stats {
    _rpc_id: 635 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    client_handle_pool,
    client_handle_pool_fraction,
    _ref,
    span_name: (__sl_span_name.len() as u16),
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    agent_hostname: (__sl_agent_hostname.len() as u16),
    os: (__sl_os.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 62 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 62 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_span_name.is_empty() {
    let __len = __sl_span_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_span_name);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_agent_hostname.is_empty() {
    let __len = __sl_agent_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_agent_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_connection_message_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  agent_hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  message: JbBlob,
  severity_: u16,
  count: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 56 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(agent_hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  __consumed = __consumed.saturating_add(message.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_agent_hostname: &[u8] = unsafe { slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
  let __sl_message: &[u8] = unsafe { slice::from_raw_parts(message.buf as *const u8, message.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agent_connection_message_stats = jb_logging__agent_connection_message_stats {
    _rpc_id: 636 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    count,
    _ref,
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    agent_hostname: (__sl_agent_hostname.len() as u16),
    os: (__sl_os.len() as u16),
    os_version: (__sl_os_version.len() as u16),
    severity_
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 56 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 56 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_agent_hostname.is_empty() {
    let __len = __sl_agent_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_agent_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
  if !__sl_message.is_empty() {
    let __len = __sl_message.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_message);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_agent_connection_message_error_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  agent_hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  message: JbBlob,
  error: JbBlob,
  count: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 56 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(agent_hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  __consumed = __consumed.saturating_add(message.len as u32);
  __consumed = __consumed.saturating_add(error.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_agent_hostname: &[u8] = unsafe { slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
  let __sl_message: &[u8] = unsafe { slice::from_raw_parts(message.buf as *const u8, message.len as usize) };
  let __sl_error: &[u8] = unsafe { slice::from_raw_parts(error.buf as *const u8, error.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__agent_connection_message_error_stats = jb_logging__agent_connection_message_error_stats {
    _rpc_id: 637 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    count,
    _ref,
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    agent_hostname: (__sl_agent_hostname.len() as u16),
    os: (__sl_os.len() as u16),
    os_version: (__sl_os_version.len() as u16),
    message: (__sl_message.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 56 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 56 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_agent_hostname.is_empty() {
    let __len = __sl_agent_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_agent_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
  if !__sl_message.is_empty() {
    let __len = __sl_message.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_message);
    __off += __len;
  }
  if !__sl_error.is_empty() {
    let __len = __sl_error.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_error);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_connection_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  agent_hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  time_since_last_message_ns: u64,
  clock_offset_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 60 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(agent_hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_agent_hostname: &[u8] = unsafe { slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__connection_stats = jb_logging__connection_stats {
    _rpc_id: 638 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    time_since_last_message_ns,
    clock_offset_ns,
    _ref,
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    agent_hostname: (__sl_agent_hostname.len() as u16),
    os: (__sl_os.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 60 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 60 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_agent_hostname.is_empty() {
    let __len = __sl_agent_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_agent_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_collector_log_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  agent_hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  severity_: JbBlob,
  count: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 50 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(agent_hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  __consumed = __consumed.saturating_add(severity_.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_agent_hostname: &[u8] = unsafe { slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
  let __sl_severity_: &[u8] = unsafe { slice::from_raw_parts(severity_.buf as *const u8, severity_.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__collector_log_stats = jb_logging__collector_log_stats {
    _rpc_id: 639 as u16,
    _len: __consumed as u16,
    count,
    time_ns,
    _ref,
    module: (__sl_module.len() as u16),
    shard,
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    agent_hostname: (__sl_agent_hostname.len() as u16),
    os: (__sl_os.len() as u16),
    os_version: (__sl_os_version.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 50 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 50 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_agent_hostname.is_empty() {
    let __len = __sl_agent_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_agent_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
  if !__sl_severity_.is_empty() {
    let __len = __sl_severity_.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_severity_);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_entry_point_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  agent_hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  kernel_headers_source: JbBlob,
  entrypoint_error: JbBlob,
  entrypoint_info: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 49 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(agent_hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  __consumed = __consumed.saturating_add(kernel_headers_source.len as u32);
  __consumed = __consumed.saturating_add(entrypoint_error.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_agent_hostname: &[u8] = unsafe { slice::from_raw_parts(agent_hostname.buf as *const u8, agent_hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
  let __sl_kernel_headers_source: &[u8] = unsafe { slice::from_raw_parts(kernel_headers_source.buf as *const u8, kernel_headers_source.len as usize) };
  let __sl_entrypoint_error: &[u8] = unsafe { slice::from_raw_parts(entrypoint_error.buf as *const u8, entrypoint_error.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__entry_point_stats = jb_logging__entry_point_stats {
    _rpc_id: 640 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    _ref,
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    agent_hostname: (__sl_agent_hostname.len() as u16),
    os: (__sl_os.len() as u16),
    os_version: (__sl_os_version.len() as u16),
    kernel_headers_source: (__sl_kernel_headers_source.len() as u16),
    entrypoint_info
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 49 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 49 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_agent_hostname.is_empty() {
    let __len = __sl_agent_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_agent_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
  if !__sl_kernel_headers_source.is_empty() {
    let __len = __sl_kernel_headers_source.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_headers_source);
    __off += __len;
  }
  if !__sl_entrypoint_error.is_empty() {
    let __len = __sl_entrypoint_error.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_entrypoint_error);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_collector_health_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  status: JbBlob,
  status_detail: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 48 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  __consumed = __consumed.saturating_add(status.len as u32);
  __consumed = __consumed.saturating_add(status_detail.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_hostname: &[u8] = unsafe { slice::from_raw_parts(hostname.buf as *const u8, hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
  let __sl_status: &[u8] = unsafe { slice::from_raw_parts(status.buf as *const u8, status.len as usize) };
  let __sl_status_detail: &[u8] = unsafe { slice::from_raw_parts(status_detail.buf as *const u8, status_detail.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__collector_health_stats = jb_logging__collector_health_stats {
    _rpc_id: 641 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    _ref,
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    hostname: (__sl_hostname.len() as u16),
    os: (__sl_os.len() as u16),
    os_version: (__sl_os_version.len() as u16),
    status: (__sl_status.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 48 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 48 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_hostname.is_empty() {
    let __len = __sl_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
  if !__sl_status.is_empty() {
    let __len = __sl_status.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_status);
    __off += __len;
  }
  if !__sl_status_detail.is_empty() {
    let __len = __sl_status_detail.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_status_detail);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_bpf_log_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  shard: u16,
  version: JbBlob,
  cloud: JbBlob,
  env: JbBlob,
  role: JbBlob,
  az: JbBlob,
  node_id: JbBlob,
  kernel_version: JbBlob,
  client_type: u16,
  hostname: JbBlob,
  os: JbBlob,
  os_version: JbBlob,
  time_ns: u64,
  filename: JbBlob,
  line: JbBlob,
  code: JbBlob,
  arg0: JbBlob,
  arg1: JbBlob,
  arg2: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 56 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  __consumed = __consumed.saturating_add(cloud.len as u32);
  __consumed = __consumed.saturating_add(env.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(node_id.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  __consumed = __consumed.saturating_add(hostname.len as u32);
  __consumed = __consumed.saturating_add(os.len as u32);
  __consumed = __consumed.saturating_add(os_version.len as u32);
  __consumed = __consumed.saturating_add(filename.len as u32);
  __consumed = __consumed.saturating_add(line.len as u32);
  __consumed = __consumed.saturating_add(code.len as u32);
  __consumed = __consumed.saturating_add(arg0.len as u32);
  __consumed = __consumed.saturating_add(arg1.len as u32);
  __consumed = __consumed.saturating_add(arg2.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
  let __sl_cloud: &[u8] = unsafe { slice::from_raw_parts(cloud.buf as *const u8, cloud.len as usize) };
  let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_node_id: &[u8] = unsafe { slice::from_raw_parts(node_id.buf as *const u8, node_id.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };
  let __sl_hostname: &[u8] = unsafe { slice::from_raw_parts(hostname.buf as *const u8, hostname.len as usize) };
  let __sl_os: &[u8] = unsafe { slice::from_raw_parts(os.buf as *const u8, os.len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
  let __sl_filename: &[u8] = unsafe { slice::from_raw_parts(filename.buf as *const u8, filename.len as usize) };
  let __sl_line: &[u8] = unsafe { slice::from_raw_parts(line.buf as *const u8, line.len as usize) };
  let __sl_code: &[u8] = unsafe { slice::from_raw_parts(code.buf as *const u8, code.len as usize) };
  let __sl_arg0: &[u8] = unsafe { slice::from_raw_parts(arg0.buf as *const u8, arg0.len as usize) };
  let __sl_arg1: &[u8] = unsafe { slice::from_raw_parts(arg1.buf as *const u8, arg1.len as usize) };
  let __sl_arg2: &[u8] = unsafe { slice::from_raw_parts(arg2.buf as *const u8, arg2.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__bpf_log_stats = jb_logging__bpf_log_stats {
    _rpc_id: 642 as u16,
    _len: __consumed as u16,
    module: (__sl_module.len() as u16),
    shard,
    time_ns,
    _ref,
    version: (__sl_version.len() as u16),
    cloud: (__sl_cloud.len() as u16),
    env: (__sl_env.len() as u16),
    role: (__sl_role.len() as u16),
    az: (__sl_az.len() as u16),
    node_id: (__sl_node_id.len() as u16),
    kernel_version: (__sl_kernel_version.len() as u16),
    client_type,
    hostname: (__sl_hostname.len() as u16),
    os: (__sl_os.len() as u16),
    os_version: (__sl_os_version.len() as u16),
    filename: (__sl_filename.len() as u16),
    line: (__sl_line.len() as u16),
    code: (__sl_code.len() as u16),
    arg0: (__sl_arg0.len() as u16),
    arg1: (__sl_arg1.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 56 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 56 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
  if !__sl_cloud.is_empty() {
    let __len = __sl_cloud.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cloud);
    __off += __len;
  }
  if !__sl_env.is_empty() {
    let __len = __sl_env.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_env);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_node_id.is_empty() {
    let __len = __sl_node_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_node_id);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
  if !__sl_hostname.is_empty() {
    let __len = __sl_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_hostname);
    __off += __len;
  }
  if !__sl_os.is_empty() {
    let __len = __sl_os.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os);
    __off += __len;
  }
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
  if !__sl_filename.is_empty() {
    let __len = __sl_filename.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_filename);
    __off += __len;
  }
  if !__sl_line.is_empty() {
    let __len = __sl_line.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_line);
    __off += __len;
  }
  if !__sl_code.is_empty() {
    let __len = __sl_code.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_code);
    __off += __len;
  }
  if !__sl_arg0.is_empty() {
    let __len = __sl_arg0.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_arg0);
    __off += __len;
  }
  if !__sl_arg1.is_empty() {
    let __len = __sl_arg1.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_arg1);
    __off += __len;
  }
  if !__sl_arg2.is_empty() {
    let __len = __sl_arg2.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_arg2);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_server_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  module: JbBlob,
  connection_counter: u64,
  disconnect_counter: u64,
  time_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 40 as u32;
  __consumed = __consumed.saturating_add(module.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_module: &[u8] = unsafe { slice::from_raw_parts(module.buf as *const u8, module.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__server_stats = jb_logging__server_stats {
    _rpc_id: 643 as u16,
    _len: __consumed as u16,
    connection_counter,
    disconnect_counter,
    time_ns,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 40 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 40 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_module.is_empty() {
    let __len = __sl_module.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_module);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_logging_encode_pulse(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 2 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_logging__pulse = jb_logging__pulse {
    _rpc_id: 65535 as u16,
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 2 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 2 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
