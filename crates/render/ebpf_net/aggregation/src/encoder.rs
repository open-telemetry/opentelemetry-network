// Auto-generated by Render: Rust FFI for ebpf_net::aggregation
#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_variables)]
#[allow(unused_imports)]
use crate::JbBlob;

use crate::wire_messages::*;

use core::slice;

#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_agg_root_start(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__agg_root_start = jb_aggregation__agg_root_start {
        _rpc_id: 461 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_agg_root_end(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 16 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__agg_root_end = jb_aggregation__agg_root_end {
        _rpc_id: 462 as u16,
        _ref,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 16 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_update_node(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    side: u8,
    id: JbBlob,
    az: JbBlob,
    role: JbBlob,
    version: JbBlob,
    env: JbBlob,
    ns: JbBlob,
    node_type: u8,
    address: JbBlob,
    process: JbBlob,
    container: JbBlob,
    pod_name: JbBlob,
    role_uid: JbBlob,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let mut __consumed: u32 = 34 as u32;
    __consumed = __consumed.saturating_add(id.len as u32);
    __consumed = __consumed.saturating_add(az.len as u32);
    __consumed = __consumed.saturating_add(role.len as u32);
    __consumed = __consumed.saturating_add(version.len as u32);
    __consumed = __consumed.saturating_add(env.len as u32);
    __consumed = __consumed.saturating_add(ns.len as u32);
    __consumed = __consumed.saturating_add(address.len as u32);
    __consumed = __consumed.saturating_add(process.len as u32);
    __consumed = __consumed.saturating_add(container.len as u32);
    __consumed = __consumed.saturating_add(pod_name.len as u32);
    __consumed = __consumed.saturating_add(role_uid.len as u32);
    assert!(__consumed <= 0xffff, "encoded len must fit in u16");

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
    let __sl_id: &[u8] = unsafe { slice::from_raw_parts(id.buf as *const u8, id.len as usize) };
    let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
    let __sl_role: &[u8] =
        unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
    let __sl_version: &[u8] =
        unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };
    let __sl_env: &[u8] = unsafe { slice::from_raw_parts(env.buf as *const u8, env.len as usize) };
    let __sl_ns: &[u8] = unsafe { slice::from_raw_parts(ns.buf as *const u8, ns.len as usize) };
    let __sl_address: &[u8] =
        unsafe { slice::from_raw_parts(address.buf as *const u8, address.len as usize) };
    let __sl_process: &[u8] =
        unsafe { slice::from_raw_parts(process.buf as *const u8, process.len as usize) };
    let __sl_container: &[u8] =
        unsafe { slice::from_raw_parts(container.buf as *const u8, container.len as usize) };
    let __sl_pod_name: &[u8] =
        unsafe { slice::from_raw_parts(pod_name.buf as *const u8, pod_name.len as usize) };
    let __sl_role_uid: &[u8] =
        unsafe { slice::from_raw_parts(role_uid.buf as *const u8, role_uid.len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__update_node = jb_aggregation__update_node {
        _rpc_id: 463 as u16,
        _len: __consumed as u16,
        id: (__sl_id.len() as u16),
        az: (__sl_az.len() as u16),
        _ref,
        role: (__sl_role.len() as u16),
        version: (__sl_version.len() as u16),
        env: (__sl_env.len() as u16),
        ns: (__sl_ns.len() as u16),
        address: (__sl_address.len() as u16),
        process: (__sl_process.len() as u16),
        container: (__sl_container.len() as u16),
        pod_name: (__sl_pod_name.len() as u16),
        side,
        node_type,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 34 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 34 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
    let mut __off = __fixed_len;
    if !__sl_id.is_empty() {
        let __len = __sl_id.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_id);
        __off += __len;
    }
    if !__sl_az.is_empty() {
        let __len = __sl_az.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_az);
        __off += __len;
    }
    if !__sl_role.is_empty() {
        let __len = __sl_role.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role);
        __off += __len;
    }
    if !__sl_version.is_empty() {
        let __len = __sl_version.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_version);
        __off += __len;
    }
    if !__sl_env.is_empty() {
        let __len = __sl_env.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_env);
        __off += __len;
    }
    if !__sl_ns.is_empty() {
        let __len = __sl_ns.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_ns);
        __off += __len;
    }
    if !__sl_address.is_empty() {
        let __len = __sl_address.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_address);
        __off += __len;
    }
    if !__sl_process.is_empty() {
        let __len = __sl_process.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_process);
        __off += __len;
    }
    if !__sl_container.is_empty() {
        let __len = __sl_container.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_container);
        __off += __len;
    }
    if !__sl_pod_name.is_empty() {
        let __len = __sl_pod_name.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_pod_name);
        __off += __len;
    }
    if !__sl_role_uid.is_empty() {
        let __len = __sl_role_uid.len();
        let __dst_seg = &mut __dst[__off..__off + __len];
        __dst_seg.copy_from_slice(__sl_role_uid);
        __off += __len;
    }
}
#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_update_tcp_metrics(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    direction: u8,
    active_sockets: u32,
    sum_retrans: u32,
    sum_bytes: u64,
    sum_srtt: u64,
    sum_delivered: u64,
    active_rtts: u32,
    syn_timeouts: u32,
    new_sockets: u32,
    tcp_resets: u32,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 60 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__update_tcp_metrics = jb_aggregation__update_tcp_metrics {
        _rpc_id: 465 as u16,
        direction,
        active_sockets,
        sum_bytes,
        sum_srtt,
        sum_delivered,
        _ref,
        sum_retrans,
        active_rtts,
        syn_timeouts,
        new_sockets,
        tcp_resets,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 60 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 60 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_update_udp_metrics(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    direction: u8,
    active_sockets: u32,
    addr_changes: u32,
    packets: u32,
    bytes: u64,
    drops: u32,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 36 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__update_udp_metrics = jb_aggregation__update_udp_metrics {
        _rpc_id: 466 as u16,
        direction,
        active_sockets,
        bytes,
        _ref,
        addr_changes,
        packets,
        drops,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 36 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 36 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_update_http_metrics(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    direction: u8,
    active_sockets: u32,
    sum_code_200: u32,
    sum_code_400: u32,
    sum_code_500: u32,
    sum_code_other: u32,
    sum_total_time_ns: u64,
    sum_processing_time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 48 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__update_http_metrics = jb_aggregation__update_http_metrics {
        _rpc_id: 467 as u16,
        direction,
        active_sockets,
        sum_total_time_ns,
        sum_processing_time_ns,
        _ref,
        sum_code_200,
        sum_code_400,
        sum_code_500,
        sum_code_other,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 48 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 48 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_update_dns_metrics(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
    _ref: u64,
    direction: u8,
    active_sockets: u32,
    requests_a: u32,
    requests_aaaa: u32,
    responses: u32,
    timeouts: u32,
    sum_total_time_ns: u64,
    sum_processing_time_ns: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 48 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__update_dns_metrics = jb_aggregation__update_dns_metrics {
        _rpc_id: 468 as u16,
        direction,
        active_sockets,
        sum_total_time_ns,
        sum_processing_time_ns,
        _ref,
        requests_a,
        requests_aaaa,
        responses,
        timeouts,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 48 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 48 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_aggregation_encode_pulse(
    __dest: *mut u8,
    __dest_len: u32,
    __tstamp: u64,
) {
    assert!(!__dest.is_null(), "dest must not be null");

    // Compute encoded length: fixed struct size + dynamic payload
    let __consumed: u32 = 2 as u32;

    let __total_len = (8_u32).saturating_add(__consumed) as usize;
    assert!(
        __total_len == __dest_len as usize,
        "dest len must exactly match computed encoded len"
    );

    // Prepare destination and input slices up front
    let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

    // Build fixed header as a stack struct using an initializer expression
    let __wire: jb_aggregation__pulse = jb_aggregation__pulse {
        _rpc_id: 65535 as u16,
    };

    // Copy timestamp and packed header (without struct tail padding)
    let __fixed_len = 8usize + 2 as usize;
    __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
    let __src_struct: &[u8] =
        unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 2 as usize) };
    __dst[8..__fixed_len].copy_from_slice(__src_struct);

    // Append dynamic payloads sequentially
}
