// Auto-generated by Render: Rust FFI for ebpf_net::ingest
#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_variables)]

#[allow(unused_imports)]
use crate::JbBlob;

use crate::wire_messages::*;

use core::slice;

#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  comm: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 24 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_comm: &[u8] = unsafe { slice::from_raw_parts(comm, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_info = jb_ingest__pid_info {
    _rpc_id: 301 as u16,
    comm: __sl_comm.try_into().unwrap(),
    pid
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 24 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 24 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_close_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  comm: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 24 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_comm: &[u8] = unsafe { slice::from_raw_parts(comm, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_close_info = jb_ingest__pid_close_info {
    _rpc_id: 306 as u16,
    comm: __sl_comm.try_into().unwrap(),
    pid
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 24 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 24 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_info_create_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  comm: *const u8,
  cgroup: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 32 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_comm: &[u8] = unsafe { slice::from_raw_parts(comm, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_info_create_deprecated = jb_ingest__pid_info_create_deprecated {
    _rpc_id: 393 as u16,
    comm: __sl_comm.try_into().unwrap(),
    pid,
    cgroup
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 32 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_info_create(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  comm: *const u8,
  cgroup: u64,
  parent_pid: i32,
  cmdline: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 36 as u32;
  __consumed = __consumed.saturating_add(cmdline.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_cmdline: &[u8] = unsafe { slice::from_raw_parts(cmdline.buf as *const u8, cmdline.len as usize) };
  let __sl_comm: &[u8] = unsafe { slice::from_raw_parts(comm, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_info_create = jb_ingest__pid_info_create {
    _rpc_id: 546 as u16,
    _len: __consumed as u16,
    pid,
    cgroup,
    parent_pid,
    comm: __sl_comm.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 36 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 36 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_cmdline.is_empty() {
    let __len = __sl_cmdline.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cmdline);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_cgroup_move(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  cgroup: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_cgroup_move = jb_ingest__pid_cgroup_move {
    _rpc_id: 397 as u16,
    pid,
    cgroup
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_set_comm(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  comm: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 24 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_comm: &[u8] = unsafe { slice::from_raw_parts(comm, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_set_comm = jb_ingest__pid_set_comm {
    _rpc_id: 399 as u16,
    comm: __sl_comm.try_into().unwrap(),
    pid
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 24 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 24 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_set_cmdline(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  cmdline: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 8 as u32;
  __consumed = __consumed.saturating_add(cmdline.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_cmdline: &[u8] = unsafe { slice::from_raw_parts(cmdline.buf as *const u8, cmdline.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_set_cmdline = jb_ingest__pid_set_cmdline {
    _rpc_id: 547 as u16,
    _len: __consumed as u16,
    pid
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 8 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 8 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_cmdline.is_empty() {
    let __len = __sl_cmdline.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cmdline);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_tracked_process_start(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__tracked_process_start = jb_ingest__tracked_process_start {
    _rpc_id: 500 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_tracked_process_end(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__tracked_process_end = jb_ingest__tracked_process_end {
    _rpc_id: 501 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_tgid(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  tgid: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_tgid = jb_ingest__set_tgid {
    _rpc_id: 502 as u16,
    tgid,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_cgroup(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  cgroup: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 24 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_cgroup = jb_ingest__set_cgroup {
    _rpc_id: 503 as u16,
    cgroup,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 24 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 24 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_command(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  command: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(command.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_command: &[u8] = unsafe { slice::from_raw_parts(command.buf as *const u8, command.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_command = jb_ingest__set_command {
    _rpc_id: 504 as u16,
    _len: __consumed as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_command.is_empty() {
    let __len = __sl_command.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_command);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pid_exit(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  tgid: u64,
  pid: u32,
  exit_code: i32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 28 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pid_exit = jb_ingest__pid_exit {
    _rpc_id: 517 as u16,
    pid,
    tgid,
    _ref,
    exit_code
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 28 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 28 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_cgroup_create_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  cgroup_parent: u64,
  name: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 88 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_name: &[u8] = unsafe { slice::from_raw_parts(name, 64) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__cgroup_create_deprecated = jb_ingest__cgroup_create_deprecated {
    _rpc_id: 394 as u16,
    name: __sl_name.try_into().unwrap(),
    cgroup,
    cgroup_parent
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 88 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 88 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_cgroup_create(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  cgroup_parent: u64,
  name: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 280 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_name: &[u8] = unsafe { slice::from_raw_parts(name, 256) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__cgroup_create = jb_ingest__cgroup_create {
    _rpc_id: 544 as u16,
    name: __sl_name.try_into().unwrap(),
    cgroup,
    cgroup_parent
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 280 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 280 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_cgroup_close(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__cgroup_close = jb_ingest__cgroup_close {
    _rpc_id: 395 as u16,
    cgroup
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_container_metadata(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  id: JbBlob,
  name: JbBlob,
  image: JbBlob,
  ip_addr: JbBlob,
  cluster: JbBlob,
  container_name: JbBlob,
  task_family: JbBlob,
  task_version: JbBlob,
  ns: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 28 as u32;
  __consumed = __consumed.saturating_add(id.len as u32);
  __consumed = __consumed.saturating_add(name.len as u32);
  __consumed = __consumed.saturating_add(image.len as u32);
  __consumed = __consumed.saturating_add(ip_addr.len as u32);
  __consumed = __consumed.saturating_add(cluster.len as u32);
  __consumed = __consumed.saturating_add(container_name.len as u32);
  __consumed = __consumed.saturating_add(task_family.len as u32);
  __consumed = __consumed.saturating_add(task_version.len as u32);
  __consumed = __consumed.saturating_add(ns.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_id: &[u8] = unsafe { slice::from_raw_parts(id.buf as *const u8, id.len as usize) };
  let __sl_name: &[u8] = unsafe { slice::from_raw_parts(name.buf as *const u8, name.len as usize) };
  let __sl_image: &[u8] = unsafe { slice::from_raw_parts(image.buf as *const u8, image.len as usize) };
  let __sl_ip_addr: &[u8] = unsafe { slice::from_raw_parts(ip_addr.buf as *const u8, ip_addr.len as usize) };
  let __sl_cluster: &[u8] = unsafe { slice::from_raw_parts(cluster.buf as *const u8, cluster.len as usize) };
  let __sl_container_name: &[u8] = unsafe { slice::from_raw_parts(container_name.buf as *const u8, container_name.len as usize) };
  let __sl_task_family: &[u8] = unsafe { slice::from_raw_parts(task_family.buf as *const u8, task_family.len as usize) };
  let __sl_task_version: &[u8] = unsafe { slice::from_raw_parts(task_version.buf as *const u8, task_version.len as usize) };
  let __sl_ns: &[u8] = unsafe { slice::from_raw_parts(ns.buf as *const u8, ns.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__container_metadata = jb_ingest__container_metadata {
    _rpc_id: 396 as u16,
    _len: __consumed as u16,
    id: (__sl_id.len() as u16),
    name: (__sl_name.len() as u16),
    cgroup,
    image: (__sl_image.len() as u16),
    ip_addr: (__sl_ip_addr.len() as u16),
    cluster: (__sl_cluster.len() as u16),
    container_name: (__sl_container_name.len() as u16),
    task_family: (__sl_task_family.len() as u16),
    task_version: (__sl_task_version.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 28 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 28 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_id.is_empty() {
    let __len = __sl_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_id);
    __off += __len;
  }
  if !__sl_name.is_empty() {
    let __len = __sl_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_name);
    __off += __len;
  }
  if !__sl_image.is_empty() {
    let __len = __sl_image.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_image);
    __off += __len;
  }
  if !__sl_ip_addr.is_empty() {
    let __len = __sl_ip_addr.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ip_addr);
    __off += __len;
  }
  if !__sl_cluster.is_empty() {
    let __len = __sl_cluster.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_cluster);
    __off += __len;
  }
  if !__sl_container_name.is_empty() {
    let __len = __sl_container_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_container_name);
    __off += __len;
  }
  if !__sl_task_family.is_empty() {
    let __len = __sl_task_family.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_task_family);
    __off += __len;
  }
  if !__sl_task_version.is_empty() {
    let __len = __sl_task_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_task_version);
    __off += __len;
  }
  if !__sl_ns.is_empty() {
    let __len = __sl_ns.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ns);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_name(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  _deprecated_pod_uid: JbBlob,
  name: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(_deprecated_pod_uid.len as u32);
  __consumed = __consumed.saturating_add(name.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl__deprecated_pod_uid: &[u8] = unsafe { slice::from_raw_parts(_deprecated_pod_uid.buf as *const u8, _deprecated_pod_uid.len as usize) };
  let __sl_name: &[u8] = unsafe { slice::from_raw_parts(name.buf as *const u8, name.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_name = jb_ingest__pod_name {
    _rpc_id: 410 as u16,
    _len: __consumed as u16,
    _deprecated_pod_uid: (__sl__deprecated_pod_uid.len() as u16),
    cgroup
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl__deprecated_pod_uid.is_empty() {
    let __len = __sl__deprecated_pod_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl__deprecated_pod_uid);
    __off += __len;
  }
  if !__sl_name.is_empty() {
    let __len = __sl_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_name);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_nomad_metadata(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  ns: JbBlob,
  group_name: JbBlob,
  task_name: JbBlob,
  job_name: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 18 as u32;
  __consumed = __consumed.saturating_add(ns.len as u32);
  __consumed = __consumed.saturating_add(group_name.len as u32);
  __consumed = __consumed.saturating_add(task_name.len as u32);
  __consumed = __consumed.saturating_add(job_name.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_ns: &[u8] = unsafe { slice::from_raw_parts(ns.buf as *const u8, ns.len as usize) };
  let __sl_group_name: &[u8] = unsafe { slice::from_raw_parts(group_name.buf as *const u8, group_name.len as usize) };
  let __sl_task_name: &[u8] = unsafe { slice::from_raw_parts(task_name.buf as *const u8, task_name.len as usize) };
  let __sl_job_name: &[u8] = unsafe { slice::from_raw_parts(job_name.buf as *const u8, job_name.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__nomad_metadata = jb_ingest__nomad_metadata {
    _rpc_id: 508 as u16,
    _len: __consumed as u16,
    ns: (__sl_ns.len() as u16),
    group_name: (__sl_group_name.len() as u16),
    cgroup,
    task_name: (__sl_task_name.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 18 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 18 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_ns.is_empty() {
    let __len = __sl_ns.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ns);
    __off += __len;
  }
  if !__sl_group_name.is_empty() {
    let __len = __sl_group_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_group_name);
    __off += __len;
  }
  if !__sl_task_name.is_empty() {
    let __len = __sl_task_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_task_name);
    __off += __len;
  }
  if !__sl_job_name.is_empty() {
    let __len = __sl_job_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_job_name);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_k8s_metadata(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  container_name: JbBlob,
  pod_name: JbBlob,
  pod_ns: JbBlob,
  pod_uid: JbBlob,
  sandbox_uid: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 20 as u32;
  __consumed = __consumed.saturating_add(container_name.len as u32);
  __consumed = __consumed.saturating_add(pod_name.len as u32);
  __consumed = __consumed.saturating_add(pod_ns.len as u32);
  __consumed = __consumed.saturating_add(pod_uid.len as u32);
  __consumed = __consumed.saturating_add(sandbox_uid.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_container_name: &[u8] = unsafe { slice::from_raw_parts(container_name.buf as *const u8, container_name.len as usize) };
  let __sl_pod_name: &[u8] = unsafe { slice::from_raw_parts(pod_name.buf as *const u8, pod_name.len as usize) };
  let __sl_pod_ns: &[u8] = unsafe { slice::from_raw_parts(pod_ns.buf as *const u8, pod_ns.len as usize) };
  let __sl_pod_uid: &[u8] = unsafe { slice::from_raw_parts(pod_uid.buf as *const u8, pod_uid.len as usize) };
  let __sl_sandbox_uid: &[u8] = unsafe { slice::from_raw_parts(sandbox_uid.buf as *const u8, sandbox_uid.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__k8s_metadata = jb_ingest__k8s_metadata {
    _rpc_id: 512 as u16,
    _len: __consumed as u16,
    container_name: (__sl_container_name.len() as u16),
    pod_name: (__sl_pod_name.len() as u16),
    cgroup,
    pod_ns: (__sl_pod_ns.len() as u16),
    pod_uid: (__sl_pod_uid.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 20 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 20 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_container_name.is_empty() {
    let __len = __sl_container_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_container_name);
    __off += __len;
  }
  if !__sl_pod_name.is_empty() {
    let __len = __sl_pod_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_pod_name);
    __off += __len;
  }
  if !__sl_pod_ns.is_empty() {
    let __len = __sl_pod_ns.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_pod_ns);
    __off += __len;
  }
  if !__sl_pod_uid.is_empty() {
    let __len = __sl_pod_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_pod_uid);
    __off += __len;
  }
  if !__sl_sandbox_uid.is_empty() {
    let __len = __sl_sandbox_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_sandbox_uid);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_k8s_metadata_port(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  port: u16,
  protocol: u8,
  name: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(name.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_name: &[u8] = unsafe { slice::from_raw_parts(name.buf as *const u8, name.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__k8s_metadata_port = jb_ingest__k8s_metadata_port {
    _rpc_id: 513 as u16,
    _len: __consumed as u16,
    port,
    protocol,
    cgroup
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_name.is_empty() {
    let __len = __sl_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_name);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_container_resource_limits_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  cpu_shares: u16,
  cpu_period: u16,
  cpu_quota: u16,
  memory_swappiness: u8,
  memory_limit: u64,
  memory_soft_limit: u64,
  total_memory_limit: i64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 41 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__container_resource_limits_deprecated = jb_ingest__container_resource_limits_deprecated {
    _rpc_id: 514 as u16,
    cpu_shares,
    cpu_period,
    cpu_quota,
    cgroup,
    memory_limit,
    memory_soft_limit,
    total_memory_limit,
    memory_swappiness
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 41 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 41 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_container_resource_limits(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  cpu_shares: u16,
  cpu_period: u32,
  cpu_quota: u32,
  memory_swappiness: u8,
  memory_limit: u64,
  memory_soft_limit: u64,
  total_memory_limit: i64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 45 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__container_resource_limits = jb_ingest__container_resource_limits {
    _rpc_id: 518 as u16,
    cpu_shares,
    cpu_period,
    cgroup,
    memory_limit,
    memory_soft_limit,
    total_memory_limit,
    cpu_quota,
    memory_swappiness
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 45 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 45 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_container_annotation(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cgroup: u64,
  key: JbBlob,
  value: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(key.len as u32);
  __consumed = __consumed.saturating_add(value.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_key: &[u8] = unsafe { slice::from_raw_parts(key.buf as *const u8, key.len as usize) };
  let __sl_value: &[u8] = unsafe { slice::from_raw_parts(value.buf as *const u8, value.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__container_annotation = jb_ingest__container_annotation {
    _rpc_id: 538 as u16,
    _len: __consumed as u16,
    key: (__sl_key.len() as u16),
    cgroup
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_key.is_empty() {
    let __len = __sl_key.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_key);
    __off += __len;
  }
  if !__sl_value.is_empty() {
    let __len = __sl_value.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_value);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_new_sock_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  sk: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__new_sock_info = jb_ingest__new_sock_info {
    _rpc_id: 302 as u16,
    pid,
    sk
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_state_ipv4(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  dest: u32,
  src: u32,
  dport: u16,
  sport: u16,
  sk: u64,
  tx_rx: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 26 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_state_ipv4 = jb_ingest__set_state_ipv4 {
    _rpc_id: 303 as u16,
    dport,
    dest,
    sk,
    src,
    tx_rx,
    sport
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 26 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 26 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_state_ipv6(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  dest: *const u8,
  src: *const u8,
  dport: u16,
  sport: u16,
  sk: u64,
  tx_rx: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 50 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_dest: &[u8] = unsafe { slice::from_raw_parts(dest, 16) };
  let __sl_src: &[u8] = unsafe { slice::from_raw_parts(src, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_state_ipv6 = jb_ingest__set_state_ipv6 {
    _rpc_id: 304 as u16,
    dport,
    tx_rx,
    sk,
    sport,
    dest: __sl_dest.try_into().unwrap(),
    src: __sl_src.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 50 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 50 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_socket_stats(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk: u64,
  diff_bytes: u64,
  diff_delivered: u32,
  diff_retrans: u32,
  max_srtt: u32,
  is_rx: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 32 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__socket_stats = jb_ingest__socket_stats {
    _rpc_id: 326 as u16,
    is_rx,
    diff_delivered,
    sk,
    diff_bytes,
    diff_retrans,
    max_srtt
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 32 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_nat_remapping(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk: u64,
  src: u32,
  dst: u32,
  sport: u16,
  dport: u16
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 22 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__nat_remapping = jb_ingest__nat_remapping {
    _rpc_id: 360 as u16,
    sport,
    src,
    sk,
    dst,
    dport
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 22 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 22 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_close_sock_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__close_sock_info = jb_ingest__close_sock_info {
    _rpc_id: 308 as u16,
    sk
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_syn_timeout(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__syn_timeout = jb_ingest__syn_timeout {
    _rpc_id: 398 as u16,
    sk
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_http_response(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk: u64,
  pid: u32,
  code: u16,
  latency_ns: u64,
  client_server: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 25 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__http_response = jb_ingest__http_response {
    _rpc_id: 401 as u16,
    code,
    pid,
    sk,
    latency_ns,
    client_server
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 25 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 25 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_tcp_reset(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk: u64,
  is_rx: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__tcp_reset = jb_ingest__tcp_reset {
    _rpc_id: 519 as u16,
    is_rx,
    sk
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_process_steady_state(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  time: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__process_steady_state = jb_ingest__process_steady_state {
    _rpc_id: 307 as u16,
    time
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_socket_steady_state(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  time: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__socket_steady_state = jb_ingest__socket_steady_state {
    _rpc_id: 309 as u16,
    time
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_version_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  major: u32,
  minor: u32,
  patch: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__version_info = jb_ingest__version_info {
    _rpc_id: 310 as u16,
    major,
    minor,
    patch
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_node_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  az: JbBlob,
  role: JbBlob,
  instance_id: JbBlob,
  instance_type: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 10 as u32;
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(role.len as u32);
  __consumed = __consumed.saturating_add(instance_id.len as u32);
  __consumed = __consumed.saturating_add(instance_type.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role.buf as *const u8, role.len as usize) };
  let __sl_instance_id: &[u8] = unsafe { slice::from_raw_parts(instance_id.buf as *const u8, instance_id.len as usize) };
  let __sl_instance_type: &[u8] = unsafe { slice::from_raw_parts(instance_type.buf as *const u8, instance_type.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_node_info = jb_ingest__set_node_info {
    _rpc_id: 415 as u16,
    _len: __consumed as u16,
    az: (__sl_az.len() as u16),
    role: (__sl_role.len() as u16),
    instance_id: (__sl_instance_id.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 10 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 10 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_role.is_empty() {
    let __len = __sl_role.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_role);
    __off += __len;
  }
  if !__sl_instance_id.is_empty() {
    let __len = __sl_instance_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_instance_id);
    __off += __len;
  }
  if !__sl_instance_type.is_empty() {
    let __len = __sl_instance_type.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_instance_type);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_config_label(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  key: JbBlob,
  value: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 6 as u32;
  __consumed = __consumed.saturating_add(key.len as u32);
  __consumed = __consumed.saturating_add(value.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_key: &[u8] = unsafe { slice::from_raw_parts(key.buf as *const u8, key.len as usize) };
  let __sl_value: &[u8] = unsafe { slice::from_raw_parts(value.buf as *const u8, value.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_config_label = jb_ingest__set_config_label {
    _rpc_id: 416 as u16,
    _len: __consumed as u16,
    key: (__sl_key.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 6 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 6 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_key.is_empty() {
    let __len = __sl_key.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_key);
    __off += __len;
  }
  if !__sl_value.is_empty() {
    let __len = __sl_value.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_value);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_availability_zone_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  retcode: u8,
  az: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 19 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_availability_zone_deprecated = jb_ingest__set_availability_zone_deprecated {
    _rpc_id: 321 as u16,
    retcode,
    az: __sl_az.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 19 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 19 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_iam_role_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  retcode: u8,
  role: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 67 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_role: &[u8] = unsafe { slice::from_raw_parts(role, 64) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_iam_role_deprecated = jb_ingest__set_iam_role_deprecated {
    _rpc_id: 322 as u16,
    retcode,
    role: __sl_role.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 67 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 67 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_instance_id_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  retcode: u8,
  id: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 20 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_id: &[u8] = unsafe { slice::from_raw_parts(id, 17) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_instance_id_deprecated = jb_ingest__set_instance_id_deprecated {
    _rpc_id: 323 as u16,
    retcode,
    id: __sl_id.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 20 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 20 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_instance_type_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  retcode: u8,
  val: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 20 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_val: &[u8] = unsafe { slice::from_raw_parts(val, 17) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_instance_type_deprecated = jb_ingest__set_instance_type_deprecated {
    _rpc_id: 324 as u16,
    retcode,
    val: __sl_val.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 20 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 20 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_dns_response_fake(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  total_dn_len: u16,
  ips: JbBlob,
  domain_name: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 8 as u32;
  __consumed = __consumed.saturating_add(ips.len as u32);
  __consumed = __consumed.saturating_add(domain_name.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_ips: &[u8] = unsafe { slice::from_raw_parts(ips.buf as *const u8, ips.len as usize) };
  let __sl_domain_name: &[u8] = unsafe { slice::from_raw_parts(domain_name.buf as *const u8, domain_name.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__dns_response_fake = jb_ingest__dns_response_fake {
    _rpc_id: 325 as u16,
    _len: __consumed as u16,
    total_dn_len,
    ips: (__sl_ips.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 8 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 8 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_ips.is_empty() {
    let __len = __sl_ips.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ips);
    __off += __len;
  }
  if !__sl_domain_name.is_empty() {
    let __len = __sl_domain_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_domain_name);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_dns_response_dep_a_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  total_dn_len: u16,
  domain_name: JbBlob,
  ipv4_addrs: JbBlob,
  ipv6_addrs: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 10 as u32;
  __consumed = __consumed.saturating_add(domain_name.len as u32);
  __consumed = __consumed.saturating_add(ipv4_addrs.len as u32);
  __consumed = __consumed.saturating_add(ipv6_addrs.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_domain_name: &[u8] = unsafe { slice::from_raw_parts(domain_name.buf as *const u8, domain_name.len as usize) };
  let __sl_ipv4_addrs: &[u8] = unsafe { slice::from_raw_parts(ipv4_addrs.buf as *const u8, ipv4_addrs.len as usize) };
  let __sl_ipv6_addrs: &[u8] = unsafe { slice::from_raw_parts(ipv6_addrs.buf as *const u8, ipv6_addrs.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__dns_response_dep_a_deprecated = jb_ingest__dns_response_dep_a_deprecated {
    _rpc_id: 391 as u16,
    _len: __consumed as u16,
    total_dn_len,
    domain_name: (__sl_domain_name.len() as u16),
    ipv4_addrs: (__sl_ipv4_addrs.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 10 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 10 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_domain_name.is_empty() {
    let __len = __sl_domain_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_domain_name);
    __off += __len;
  }
  if !__sl_ipv4_addrs.is_empty() {
    let __len = __sl_ipv4_addrs.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ipv4_addrs);
    __off += __len;
  }
  if !__sl_ipv6_addrs.is_empty() {
    let __len = __sl_ipv6_addrs.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ipv6_addrs);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_set_config_label_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  key: *const u8,
  val: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 62 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_key: &[u8] = unsafe { slice::from_raw_parts(key, 20) };
  let __sl_val: &[u8] = unsafe { slice::from_raw_parts(val, 40) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__set_config_label_deprecated = jb_ingest__set_config_label_deprecated {
    _rpc_id: 327 as u16,
    key: __sl_key.try_into().unwrap(),
    val: __sl_val.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 62 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 62 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_api_key(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  tenant: *const u8,
  api_key: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 86 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_tenant: &[u8] = unsafe { slice::from_raw_parts(tenant, 20) };
  let __sl_api_key: &[u8] = unsafe { slice::from_raw_parts(api_key, 64) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__api_key = jb_ingest__api_key {
    _rpc_id: 352 as u16,
    tenant: __sl_tenant.try_into().unwrap(),
    api_key: __sl_api_key.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 86 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 86 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_private_ipv4_addr(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  addr: u32,
  vpc_id: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 28 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_vpc_id: &[u8] = unsafe { slice::from_raw_parts(vpc_id, 22) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__private_ipv4_addr = jb_ingest__private_ipv4_addr {
    _rpc_id: 353 as u16,
    vpc_id: __sl_vpc_id.try_into().unwrap(),
    addr
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 28 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 28 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_ipv6_addr(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  addr: *const u8,
  vpc_id: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 40 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_addr: &[u8] = unsafe { slice::from_raw_parts(addr, 16) };
  let __sl_vpc_id: &[u8] = unsafe { slice::from_raw_parts(vpc_id, 22) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__ipv6_addr = jb_ingest__ipv6_addr {
    _rpc_id: 354 as u16,
    addr: __sl_addr.try_into().unwrap(),
    vpc_id: __sl_vpc_id.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 40 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 40 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_public_to_private_ipv4(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  public_addr: u32,
  private_addr: u32,
  vpc_id: *const u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 32 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_vpc_id: &[u8] = unsafe { slice::from_raw_parts(vpc_id, 22) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__public_to_private_ipv4 = jb_ingest__public_to_private_ipv4 {
    _rpc_id: 355 as u16,
    vpc_id: __sl_vpc_id.try_into().unwrap(),
    public_addr,
    private_addr
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 32 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_metadata_complete(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  time: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__metadata_complete = jb_ingest__metadata_complete {
    _rpc_id: 356 as u16,
    time
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_bpf_lost_samples(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  count: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__bpf_lost_samples = jb_ingest__bpf_lost_samples {
    _rpc_id: 357 as u16,
    count
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_new_legacy(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  uid: JbBlob,
  ip: u32,
  owner_name: JbBlob,
  owner_kind: u8,
  owner_uid: JbBlob,
  is_host_network: u8,
  ns: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(uid.len as u32);
  __consumed = __consumed.saturating_add(owner_name.len as u32);
  __consumed = __consumed.saturating_add(owner_uid.len as u32);
  __consumed = __consumed.saturating_add(ns.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };
  let __sl_owner_name: &[u8] = unsafe { slice::from_raw_parts(owner_name.buf as *const u8, owner_name.len as usize) };
  let __sl_owner_uid: &[u8] = unsafe { slice::from_raw_parts(owner_uid.buf as *const u8, owner_uid.len as usize) };
  let __sl_ns: &[u8] = unsafe { slice::from_raw_parts(ns.buf as *const u8, ns.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_new_legacy = jb_ingest__pod_new_legacy {
    _rpc_id: 358 as u16,
    _len: __consumed as u16,
    ip,
    uid: (__sl_uid.len() as u16),
    owner_name: (__sl_owner_name.len() as u16),
    owner_uid: (__sl_owner_uid.len() as u16),
    owner_kind,
    is_host_network
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_uid.is_empty() {
    let __len = __sl_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_uid);
    __off += __len;
  }
  if !__sl_owner_name.is_empty() {
    let __len = __sl_owner_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_owner_name);
    __off += __len;
  }
  if !__sl_owner_uid.is_empty() {
    let __len = __sl_owner_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_owner_uid);
    __off += __len;
  }
  if !__sl_ns.is_empty() {
    let __len = __sl_ns.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ns);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_new_legacy2(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  uid: JbBlob,
  ip: u32,
  owner_name: JbBlob,
  owner_kind: u8,
  owner_uid: JbBlob,
  is_host_network: u8,
  ns: JbBlob,
  version: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 18 as u32;
  __consumed = __consumed.saturating_add(uid.len as u32);
  __consumed = __consumed.saturating_add(owner_name.len as u32);
  __consumed = __consumed.saturating_add(owner_uid.len as u32);
  __consumed = __consumed.saturating_add(ns.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };
  let __sl_owner_name: &[u8] = unsafe { slice::from_raw_parts(owner_name.buf as *const u8, owner_name.len as usize) };
  let __sl_owner_uid: &[u8] = unsafe { slice::from_raw_parts(owner_uid.buf as *const u8, owner_uid.len as usize) };
  let __sl_ns: &[u8] = unsafe { slice::from_raw_parts(ns.buf as *const u8, ns.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_new_legacy2 = jb_ingest__pod_new_legacy2 {
    _rpc_id: 414 as u16,
    _len: __consumed as u16,
    ip,
    uid: (__sl_uid.len() as u16),
    owner_name: (__sl_owner_name.len() as u16),
    owner_uid: (__sl_owner_uid.len() as u16),
    ns: (__sl_ns.len() as u16),
    owner_kind,
    is_host_network
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 18 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 18 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_uid.is_empty() {
    let __len = __sl_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_uid);
    __off += __len;
  }
  if !__sl_owner_name.is_empty() {
    let __len = __sl_owner_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_owner_name);
    __off += __len;
  }
  if !__sl_owner_uid.is_empty() {
    let __len = __sl_owner_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_owner_uid);
    __off += __len;
  }
  if !__sl_ns.is_empty() {
    let __len = __sl_ns.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ns);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_new_with_name(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  uid: JbBlob,
  ip: u32,
  owner_name: JbBlob,
  pod_name: JbBlob,
  owner_kind: u8,
  owner_uid: JbBlob,
  is_host_network: u8,
  ns: JbBlob,
  version: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 20 as u32;
  __consumed = __consumed.saturating_add(uid.len as u32);
  __consumed = __consumed.saturating_add(owner_name.len as u32);
  __consumed = __consumed.saturating_add(pod_name.len as u32);
  __consumed = __consumed.saturating_add(owner_uid.len as u32);
  __consumed = __consumed.saturating_add(ns.len as u32);
  __consumed = __consumed.saturating_add(version.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };
  let __sl_owner_name: &[u8] = unsafe { slice::from_raw_parts(owner_name.buf as *const u8, owner_name.len as usize) };
  let __sl_pod_name: &[u8] = unsafe { slice::from_raw_parts(pod_name.buf as *const u8, pod_name.len as usize) };
  let __sl_owner_uid: &[u8] = unsafe { slice::from_raw_parts(owner_uid.buf as *const u8, owner_uid.len as usize) };
  let __sl_ns: &[u8] = unsafe { slice::from_raw_parts(ns.buf as *const u8, ns.len as usize) };
  let __sl_version: &[u8] = unsafe { slice::from_raw_parts(version.buf as *const u8, version.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_new_with_name = jb_ingest__pod_new_with_name {
    _rpc_id: 515 as u16,
    _len: __consumed as u16,
    ip,
    uid: (__sl_uid.len() as u16),
    owner_name: (__sl_owner_name.len() as u16),
    pod_name: (__sl_pod_name.len() as u16),
    owner_uid: (__sl_owner_uid.len() as u16),
    ns: (__sl_ns.len() as u16),
    owner_kind,
    is_host_network
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 20 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 20 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_uid.is_empty() {
    let __len = __sl_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_uid);
    __off += __len;
  }
  if !__sl_owner_name.is_empty() {
    let __len = __sl_owner_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_owner_name);
    __off += __len;
  }
  if !__sl_pod_name.is_empty() {
    let __len = __sl_pod_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_pod_name);
    __off += __len;
  }
  if !__sl_owner_uid.is_empty() {
    let __len = __sl_owner_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_owner_uid);
    __off += __len;
  }
  if !__sl_ns.is_empty() {
    let __len = __sl_ns.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ns);
    __off += __len;
  }
  if !__sl_version.is_empty() {
    let __len = __sl_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_version);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_container_legacy(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  uid: JbBlob,
  container_id: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 6 as u32;
  __consumed = __consumed.saturating_add(uid.len as u32);
  __consumed = __consumed.saturating_add(container_id.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };
  let __sl_container_id: &[u8] = unsafe { slice::from_raw_parts(container_id.buf as *const u8, container_id.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_container_legacy = jb_ingest__pod_container_legacy {
    _rpc_id: 400 as u16,
    _len: __consumed as u16,
    uid: (__sl_uid.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 6 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 6 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_uid.is_empty() {
    let __len = __sl_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_uid);
    __off += __len;
  }
  if !__sl_container_id.is_empty() {
    let __len = __sl_container_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_container_id);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_container(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  uid: JbBlob,
  container_id: JbBlob,
  container_name: JbBlob,
  container_image: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 10 as u32;
  __consumed = __consumed.saturating_add(uid.len as u32);
  __consumed = __consumed.saturating_add(container_id.len as u32);
  __consumed = __consumed.saturating_add(container_name.len as u32);
  __consumed = __consumed.saturating_add(container_image.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };
  let __sl_container_id: &[u8] = unsafe { slice::from_raw_parts(container_id.buf as *const u8, container_id.len as usize) };
  let __sl_container_name: &[u8] = unsafe { slice::from_raw_parts(container_name.buf as *const u8, container_name.len as usize) };
  let __sl_container_image: &[u8] = unsafe { slice::from_raw_parts(container_image.buf as *const u8, container_image.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_container = jb_ingest__pod_container {
    _rpc_id: 494 as u16,
    _len: __consumed as u16,
    uid: (__sl_uid.len() as u16),
    container_id: (__sl_container_id.len() as u16),
    container_name: (__sl_container_name.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 10 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 10 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_uid.is_empty() {
    let __len = __sl_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_uid);
    __off += __len;
  }
  if !__sl_container_id.is_empty() {
    let __len = __sl_container_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_container_id);
    __off += __len;
  }
  if !__sl_container_name.is_empty() {
    let __len = __sl_container_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_container_name);
    __off += __len;
  }
  if !__sl_container_image.is_empty() {
    let __len = __sl_container_image.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_container_image);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_delete(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  uid: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 4 as u32;
  __consumed = __consumed.saturating_add(uid.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_uid: &[u8] = unsafe { slice::from_raw_parts(uid.buf as *const u8, uid.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_delete = jb_ingest__pod_delete {
    _rpc_id: 359 as u16,
    _len: __consumed as u16,
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 4 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 4 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_uid.is_empty() {
    let __len = __sl_uid.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_uid);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pod_resync(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  resync_count: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pod_resync = jb_ingest__pod_resync {
    _rpc_id: 390 as u16,
    resync_count
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_span_duration_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  duration: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__span_duration_info = jb_ingest__span_duration_info {
    _rpc_id: 351 as u16,
    duration
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_heartbeat(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 2 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__heartbeat = jb_ingest__heartbeat {
    _rpc_id: 392 as u16,
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 2 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 2 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_connect(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  collector_type: u8,
  hostname: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 5 as u32;
  __consumed = __consumed.saturating_add(hostname.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_hostname: &[u8] = unsafe { slice::from_raw_parts(hostname.buf as *const u8, hostname.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__connect = jb_ingest__connect {
    _rpc_id: 548 as u16,
    _len: __consumed as u16,
    collector_type
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 5 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 5 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_hostname.is_empty() {
    let __len = __sl_hostname.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_hostname);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_health_check(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  client_type: u8,
  origin: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 5 as u32;
  __consumed = __consumed.saturating_add(origin.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_origin: &[u8] = unsafe { slice::from_raw_parts(origin.buf as *const u8, origin.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__health_check = jb_ingest__health_check {
    _rpc_id: 409 as u16,
    _len: __consumed as u16,
    client_type
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 5 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 5 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_origin.is_empty() {
    let __len = __sl_origin.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_origin);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_log_message(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  log_level: u8,
  message: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 5 as u32;
  __consumed = __consumed.saturating_add(message.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_message: &[u8] = unsafe { slice::from_raw_parts(message.buf as *const u8, message.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__log_message = jb_ingest__log_message {
    _rpc_id: 411 as u16,
    _len: __consumed as u16,
    log_level
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 5 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 5 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_message.is_empty() {
    let __len = __sl_message.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_message);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_agent_resource_usage(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  user_mode_time_us: u64,
  kernel_mode_time_us: u64,
  max_resident_set_size: u64,
  minor_page_faults: u32,
  major_page_faults: u32,
  block_input_count: u32,
  block_output_count: u32,
  voluntary_context_switch_count: u32,
  involuntary_context_switch_count: u32,
  cpu_usage_by_agent: u16,
  cpu_idle: u16
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 54 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__agent_resource_usage = jb_ingest__agent_resource_usage {
    _rpc_id: 412 as u16,
    cpu_usage_by_agent,
    minor_page_faults,
    user_mode_time_us,
    kernel_mode_time_us,
    max_resident_set_size,
    major_page_faults,
    block_input_count,
    block_output_count,
    voluntary_context_switch_count,
    involuntary_context_switch_count,
    cpu_idle
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 54 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 54 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_cloud_platform(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cloud_platform: u16
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 4 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__cloud_platform = jb_ingest__cloud_platform {
    _rpc_id: 413 as u16,
    cloud_platform
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 4 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 4 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_os_info_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  os: u8,
  flavor: u8,
  kernel_version: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 6 as u32;
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__os_info_deprecated = jb_ingest__os_info_deprecated {
    _rpc_id: 419 as u16,
    _len: __consumed as u16,
    os,
    flavor
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 6 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 6 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_os_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  os: u8,
  flavor: u8,
  os_version: JbBlob,
  kernel_version: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 8 as u32;
  __consumed = __consumed.saturating_add(os_version.len as u32);
  __consumed = __consumed.saturating_add(kernel_version.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_os_version: &[u8] = unsafe { slice::from_raw_parts(os_version.buf as *const u8, os_version.len as usize) };
  let __sl_kernel_version: &[u8] = unsafe { slice::from_raw_parts(kernel_version.buf as *const u8, kernel_version.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__os_info = jb_ingest__os_info {
    _rpc_id: 545 as u16,
    _len: __consumed as u16,
    os_version: (__sl_os_version.len() as u16),
    os,
    flavor
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 8 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 8 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_os_version.is_empty() {
    let __len = __sl_os_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_os_version);
    __off += __len;
  }
  if !__sl_kernel_version.is_empty() {
    let __len = __sl_kernel_version.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_kernel_version);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_kernel_headers_source(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  source: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 3 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__kernel_headers_source = jb_ingest__kernel_headers_source {
    _rpc_id: 420 as u16,
    source
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 3 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 3 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_entrypoint_error(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  error: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 3 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__entrypoint_error = jb_ingest__entrypoint_error {
    _rpc_id: 491 as u16,
    error
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 3 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 3 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_bpf_compiled(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 2 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__bpf_compiled = jb_ingest__bpf_compiled {
    _rpc_id: 492 as u16,
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 2 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 2 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_begin_telemetry(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 2 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__begin_telemetry = jb_ingest__begin_telemetry {
    _rpc_id: 493 as u16,
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 2 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 2 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_cloud_platform_account_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  account_id: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 4 as u32;
  __consumed = __consumed.saturating_add(account_id.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_account_id: &[u8] = unsafe { slice::from_raw_parts(account_id.buf as *const u8, account_id.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__cloud_platform_account_info = jb_ingest__cloud_platform_account_info {
    _rpc_id: 495 as u16,
    _len: __consumed as u16,
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 4 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 4 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_account_id.is_empty() {
    let __len = __sl_account_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_account_id);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_collector_health(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  status: u16,
  detail: u16
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 6 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__collector_health = jb_ingest__collector_health {
    _rpc_id: 496 as u16,
    status,
    detail
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 6 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 6 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_system_wide_process_settings(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  clock_ticks_per_second: u64,
  memory_page_bytes: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 24 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__system_wide_process_settings = jb_ingest__system_wide_process_settings {
    _rpc_id: 498 as u16,
    clock_ticks_per_second,
    memory_page_bytes
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 24 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 24 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_collect_blob(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  blob_type: u16,
  subtype: u64,
  metadata: JbBlob,
  blob: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 16 as u32;
  __consumed = __consumed.saturating_add(metadata.len as u32);
  __consumed = __consumed.saturating_add(blob.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_metadata: &[u8] = unsafe { slice::from_raw_parts(metadata.buf as *const u8, metadata.len as usize) };
  let __sl_blob: &[u8] = unsafe { slice::from_raw_parts(blob.buf as *const u8, blob.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__collect_blob = jb_ingest__collect_blob {
    _rpc_id: 511 as u16,
    _len: __consumed as u16,
    blob_type,
    metadata: (__sl_metadata.len() as u16),
    subtype
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_metadata.is_empty() {
    let __len = __sl_metadata.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_metadata);
    __off += __len;
  }
  if !__sl_blob.is_empty() {
    let __len = __sl_blob.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_blob);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_report_cpu_cores(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  cpu_core_count: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 8 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__report_cpu_cores = jb_ingest__report_cpu_cores {
    _rpc_id: 536 as u16,
    cpu_core_count
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 8 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 8 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_bpf_log(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  filename: JbBlob,
  line: u32,
  code: u64,
  arg0: u64,
  arg1: u64,
  arg2: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 40 as u32;
  __consumed = __consumed.saturating_add(filename.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_filename: &[u8] = unsafe { slice::from_raw_parts(filename.buf as *const u8, filename.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__bpf_log = jb_ingest__bpf_log {
    _rpc_id: 537 as u16,
    _len: __consumed as u16,
    line,
    code,
    arg0,
    arg1,
    arg2
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 40 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 40 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_filename.is_empty() {
    let __len = __sl_filename.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_filename);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_aws_network_interface_start(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  ip: u128
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 32 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__aws_network_interface_start = jb_ingest__aws_network_interface_start {
    _rpc_id: 406 as u16,
    _ref,
    ip
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 32 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 32 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_aws_network_interface_end(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__aws_network_interface_end = jb_ingest__aws_network_interface_end {
    _rpc_id: 407 as u16,
    _ref
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_network_interface_info_deprecated(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  ip_owner_id: *const u8,
  vpc_id: *const u8,
  az: *const u8,
  interface_id: JbBlob,
  interface_type: u16,
  instance_id: JbBlob,
  instance_owner_id: JbBlob,
  public_dns_name: JbBlob,
  private_dns_name: JbBlob,
  interface_description: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 80 as u32;
  __consumed = __consumed.saturating_add(interface_id.len as u32);
  __consumed = __consumed.saturating_add(instance_id.len as u32);
  __consumed = __consumed.saturating_add(instance_owner_id.len as u32);
  __consumed = __consumed.saturating_add(public_dns_name.len as u32);
  __consumed = __consumed.saturating_add(private_dns_name.len as u32);
  __consumed = __consumed.saturating_add(interface_description.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_interface_id: &[u8] = unsafe { slice::from_raw_parts(interface_id.buf as *const u8, interface_id.len as usize) };
  let __sl_instance_id: &[u8] = unsafe { slice::from_raw_parts(instance_id.buf as *const u8, instance_id.len as usize) };
  let __sl_instance_owner_id: &[u8] = unsafe { slice::from_raw_parts(instance_owner_id.buf as *const u8, instance_owner_id.len as usize) };
  let __sl_public_dns_name: &[u8] = unsafe { slice::from_raw_parts(public_dns_name.buf as *const u8, public_dns_name.len as usize) };
  let __sl_private_dns_name: &[u8] = unsafe { slice::from_raw_parts(private_dns_name.buf as *const u8, private_dns_name.len as usize) };
  let __sl_interface_description: &[u8] = unsafe { slice::from_raw_parts(interface_description.buf as *const u8, interface_description.len as usize) };
  let __sl_ip_owner_id: &[u8] = unsafe { slice::from_raw_parts(ip_owner_id, 18) };
  let __sl_vpc_id: &[u8] = unsafe { slice::from_raw_parts(vpc_id, 22) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__network_interface_info_deprecated = jb_ingest__network_interface_info_deprecated {
    _rpc_id: 408 as u16,
    _len: __consumed as u16,
    interface_id: (__sl_interface_id.len() as u16),
    interface_type,
    _ref,
    instance_id: (__sl_instance_id.len() as u16),
    instance_owner_id: (__sl_instance_owner_id.len() as u16),
    public_dns_name: (__sl_public_dns_name.len() as u16),
    private_dns_name: (__sl_private_dns_name.len() as u16),
    ip_owner_id: __sl_ip_owner_id.try_into().unwrap(),
    vpc_id: __sl_vpc_id.try_into().unwrap(),
    az: __sl_az.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 80 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 80 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_interface_id.is_empty() {
    let __len = __sl_interface_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_interface_id);
    __off += __len;
  }
  if !__sl_instance_id.is_empty() {
    let __len = __sl_instance_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_instance_id);
    __off += __len;
  }
  if !__sl_instance_owner_id.is_empty() {
    let __len = __sl_instance_owner_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_instance_owner_id);
    __off += __len;
  }
  if !__sl_public_dns_name.is_empty() {
    let __len = __sl_public_dns_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_public_dns_name);
    __off += __len;
  }
  if !__sl_private_dns_name.is_empty() {
    let __len = __sl_private_dns_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_private_dns_name);
    __off += __len;
  }
  if !__sl_interface_description.is_empty() {
    let __len = __sl_interface_description.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_interface_description);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_network_interface_info(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  _ref: u64,
  ip_owner_id: JbBlob,
  vpc_id: JbBlob,
  az: JbBlob,
  interface_id: JbBlob,
  interface_type: u16,
  instance_id: JbBlob,
  instance_owner_id: JbBlob,
  public_dns_name: JbBlob,
  private_dns_name: JbBlob,
  interface_description: JbBlob
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 30 as u32;
  __consumed = __consumed.saturating_add(ip_owner_id.len as u32);
  __consumed = __consumed.saturating_add(vpc_id.len as u32);
  __consumed = __consumed.saturating_add(az.len as u32);
  __consumed = __consumed.saturating_add(interface_id.len as u32);
  __consumed = __consumed.saturating_add(instance_id.len as u32);
  __consumed = __consumed.saturating_add(instance_owner_id.len as u32);
  __consumed = __consumed.saturating_add(public_dns_name.len as u32);
  __consumed = __consumed.saturating_add(private_dns_name.len as u32);
  __consumed = __consumed.saturating_add(interface_description.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_ip_owner_id: &[u8] = unsafe { slice::from_raw_parts(ip_owner_id.buf as *const u8, ip_owner_id.len as usize) };
  let __sl_vpc_id: &[u8] = unsafe { slice::from_raw_parts(vpc_id.buf as *const u8, vpc_id.len as usize) };
  let __sl_az: &[u8] = unsafe { slice::from_raw_parts(az.buf as *const u8, az.len as usize) };
  let __sl_interface_id: &[u8] = unsafe { slice::from_raw_parts(interface_id.buf as *const u8, interface_id.len as usize) };
  let __sl_instance_id: &[u8] = unsafe { slice::from_raw_parts(instance_id.buf as *const u8, instance_id.len as usize) };
  let __sl_instance_owner_id: &[u8] = unsafe { slice::from_raw_parts(instance_owner_id.buf as *const u8, instance_owner_id.len as usize) };
  let __sl_public_dns_name: &[u8] = unsafe { slice::from_raw_parts(public_dns_name.buf as *const u8, public_dns_name.len as usize) };
  let __sl_private_dns_name: &[u8] = unsafe { slice::from_raw_parts(private_dns_name.buf as *const u8, private_dns_name.len as usize) };
  let __sl_interface_description: &[u8] = unsafe { slice::from_raw_parts(interface_description.buf as *const u8, interface_description.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__network_interface_info = jb_ingest__network_interface_info {
    _rpc_id: 417 as u16,
    _len: __consumed as u16,
    ip_owner_id: (__sl_ip_owner_id.len() as u16),
    vpc_id: (__sl_vpc_id.len() as u16),
    _ref,
    az: (__sl_az.len() as u16),
    interface_id: (__sl_interface_id.len() as u16),
    interface_type,
    instance_id: (__sl_instance_id.len() as u16),
    instance_owner_id: (__sl_instance_owner_id.len() as u16),
    public_dns_name: (__sl_public_dns_name.len() as u16),
    private_dns_name: (__sl_private_dns_name.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 30 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 30 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_ip_owner_id.is_empty() {
    let __len = __sl_ip_owner_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ip_owner_id);
    __off += __len;
  }
  if !__sl_vpc_id.is_empty() {
    let __len = __sl_vpc_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_vpc_id);
    __off += __len;
  }
  if !__sl_az.is_empty() {
    let __len = __sl_az.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_az);
    __off += __len;
  }
  if !__sl_interface_id.is_empty() {
    let __len = __sl_interface_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_interface_id);
    __off += __len;
  }
  if !__sl_instance_id.is_empty() {
    let __len = __sl_instance_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_instance_id);
    __off += __len;
  }
  if !__sl_instance_owner_id.is_empty() {
    let __len = __sl_instance_owner_id.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_instance_owner_id);
    __off += __len;
  }
  if !__sl_public_dns_name.is_empty() {
    let __len = __sl_public_dns_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_public_dns_name);
    __off += __len;
  }
  if !__sl_private_dns_name.is_empty() {
    let __len = __sl_private_dns_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_private_dns_name);
    __off += __len;
  }
  if !__sl_interface_description.is_empty() {
    let __len = __sl_interface_description.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_interface_description);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_udp_new_socket(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  pid: u32,
  sk_id: u32,
  laddr: *const u8,
  lport: u16
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 28 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_laddr: &[u8] = unsafe { slice::from_raw_parts(laddr, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__udp_new_socket = jb_ingest__udp_new_socket {
    _rpc_id: 328 as u16,
    lport,
    pid,
    sk_id,
    laddr: __sl_laddr.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 28 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 28 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_udp_stats_addr_unchanged(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32,
  is_rx: u8,
  packets: u32,
  bytes: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 16 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__udp_stats_addr_unchanged = jb_ingest__udp_stats_addr_unchanged {
    _rpc_id: 330 as u16,
    is_rx,
    sk_id,
    packets,
    bytes
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 16 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 16 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_udp_stats_addr_changed_v4(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32,
  is_rx: u8,
  packets: u32,
  bytes: u32,
  raddr: u32,
  rport: u16
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 21 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__udp_stats_addr_changed_v4 = jb_ingest__udp_stats_addr_changed_v4 {
    _rpc_id: 341 as u16,
    rport,
    sk_id,
    packets,
    bytes,
    raddr,
    is_rx
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 21 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 21 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_udp_stats_addr_changed_v6(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32,
  is_rx: u8,
  packets: u32,
  bytes: u32,
  raddr: *const u8,
  rport: u16
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 33 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_raddr: &[u8] = unsafe { slice::from_raw_parts(raddr, 16) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__udp_stats_addr_changed_v6 = jb_ingest__udp_stats_addr_changed_v6 {
    _rpc_id: 350 as u16,
    rport,
    sk_id,
    packets,
    bytes,
    is_rx,
    raddr: __sl_raddr.try_into().unwrap()
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 33 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 33 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_dns_response_dep_b(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32,
  total_dn_len: u16,
  domain_name: JbBlob,
  ipv4_addrs: JbBlob,
  ipv6_addrs: JbBlob,
  latency_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 22 as u32;
  __consumed = __consumed.saturating_add(domain_name.len as u32);
  __consumed = __consumed.saturating_add(ipv4_addrs.len as u32);
  __consumed = __consumed.saturating_add(ipv6_addrs.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_domain_name: &[u8] = unsafe { slice::from_raw_parts(domain_name.buf as *const u8, domain_name.len as usize) };
  let __sl_ipv4_addrs: &[u8] = unsafe { slice::from_raw_parts(ipv4_addrs.buf as *const u8, ipv4_addrs.len as usize) };
  let __sl_ipv6_addrs: &[u8] = unsafe { slice::from_raw_parts(ipv6_addrs.buf as *const u8, ipv6_addrs.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__dns_response_dep_b = jb_ingest__dns_response_dep_b {
    _rpc_id: 402 as u16,
    _len: __consumed as u16,
    sk_id,
    latency_ns,
    total_dn_len,
    domain_name: (__sl_domain_name.len() as u16),
    ipv4_addrs: (__sl_ipv4_addrs.len() as u16)
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 22 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 22 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_domain_name.is_empty() {
    let __len = __sl_domain_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_domain_name);
    __off += __len;
  }
  if !__sl_ipv4_addrs.is_empty() {
    let __len = __sl_ipv4_addrs.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ipv4_addrs);
    __off += __len;
  }
  if !__sl_ipv6_addrs.is_empty() {
    let __len = __sl_ipv6_addrs.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ipv6_addrs);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_dns_timeout(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32,
  total_dn_len: u16,
  domain_name: JbBlob,
  timeout_ns: u64
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 18 as u32;
  __consumed = __consumed.saturating_add(domain_name.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_domain_name: &[u8] = unsafe { slice::from_raw_parts(domain_name.buf as *const u8, domain_name.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__dns_timeout = jb_ingest__dns_timeout {
    _rpc_id: 403 as u16,
    _len: __consumed as u16,
    sk_id,
    timeout_ns,
    total_dn_len
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 18 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 18 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_domain_name.is_empty() {
    let __len = __sl_domain_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_domain_name);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_udp_stats_drops_changed(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32,
  drops: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 12 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__udp_stats_drops_changed = jb_ingest__udp_stats_drops_changed {
    _rpc_id: 405 as u16,
    sk_id,
    drops
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 12 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 12 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_dns_response(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32,
  total_dn_len: u16,
  domain_name: JbBlob,
  ipv4_addrs: JbBlob,
  ipv6_addrs: JbBlob,
  latency_ns: u64,
  client_server: u8
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let mut __consumed: u32 = 23 as u32;
  __consumed = __consumed.saturating_add(domain_name.len as u32);
  __consumed = __consumed.saturating_add(ipv4_addrs.len as u32);
  __consumed = __consumed.saturating_add(ipv6_addrs.len as u32);
  assert!(__consumed <= 0xffff, "encoded len must fit in u16");

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };
  let __sl_domain_name: &[u8] = unsafe { slice::from_raw_parts(domain_name.buf as *const u8, domain_name.len as usize) };
  let __sl_ipv4_addrs: &[u8] = unsafe { slice::from_raw_parts(ipv4_addrs.buf as *const u8, ipv4_addrs.len as usize) };
  let __sl_ipv6_addrs: &[u8] = unsafe { slice::from_raw_parts(ipv6_addrs.buf as *const u8, ipv6_addrs.len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__dns_response = jb_ingest__dns_response {
    _rpc_id: 418 as u16,
    _len: __consumed as u16,
    sk_id,
    latency_ns,
    total_dn_len,
    domain_name: (__sl_domain_name.len() as u16),
    ipv4_addrs: (__sl_ipv4_addrs.len() as u16),
    client_server
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 23 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 23 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
  let mut __off = __fixed_len;
  if !__sl_domain_name.is_empty() {
    let __len = __sl_domain_name.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_domain_name);
    __off += __len;
  }
  if !__sl_ipv4_addrs.is_empty() {
    let __len = __sl_ipv4_addrs.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ipv4_addrs);
    __off += __len;
  }
  if !__sl_ipv6_addrs.is_empty() {
    let __len = __sl_ipv6_addrs.len();
    let __dst_seg = &mut __dst[__off .. __off + __len];
    __dst_seg.copy_from_slice(__sl_ipv6_addrs);
    __off += __len;
  }
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_udp_destroy_socket(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64,
  sk_id: u32
) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 8 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__udp_destroy_socket = jb_ingest__udp_destroy_socket {
    _rpc_id: 329 as u16,
    sk_id
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 8 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 8 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
#[no_mangle]
pub extern "C" fn ebpf_net_ingest_encode_pulse(
  __dest: *mut u8,
  __dest_len: u32,
  __tstamp: u64) {
  assert!(!__dest.is_null(), "dest must not be null");

  // Compute encoded length: fixed struct size + dynamic payload
  let __consumed: u32 = 2 as u32;

  let __total_len = (8_u32).saturating_add(__consumed) as usize;
  assert!(
    __total_len == __dest_len as usize,
    "dest len must exactly match computed encoded len"
  );

  // Prepare destination and input slices up front
  let __dst: &mut [u8] = unsafe { slice::from_raw_parts_mut(__dest, __dest_len as usize) };

  // Build fixed header as a stack struct using an initializer expression
  let __wire: jb_ingest__pulse = jb_ingest__pulse {
    _rpc_id: 65535 as u16,
  };

  // Copy timestamp and packed header (without struct tail padding)
  let __fixed_len = 8usize + 2 as usize;
  __dst[..8].copy_from_slice(&__tstamp.to_ne_bytes());
  let __src_struct: &[u8] = unsafe { slice::from_raw_parts(&__wire as *const _ as *const u8, 2 as usize) };
  __dst[8..__fixed_len].copy_from_slice(__src_struct);

  // Append dynamic payloads sequentially
}
